{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T16:39:33.351056Z","iopub.execute_input":"2026-01-06T16:39:33.351629Z","iopub.status.idle":"2026-01-06T16:39:40.863031Z","shell.execute_reply.started":"2026-01-06T16:39:33.351600Z","shell.execute_reply":"2026-01-06T16:39:40.862314Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.20.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nCollecting pyarrow>=21.0.0 (from datasets)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pyarrow-22.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================\n# CORE SCIENTIFIC COMPUTING\n# ============================================\nimport numpy as np\nimport pandas as pd\n\n# ============================================\n# VISUALIZATION\n# ============================================\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# ============================================\n# MACHINE LEARNING - SKLEARN\n# ============================================\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.multioutput import ClassifierChain\nfrom sklearn.utils import resample\n\n# Metrics\nfrom sklearn.metrics import (\n    f1_score, \n    hamming_loss, \n    accuracy_score, \n    jaccard_score,\n    precision_score, \n    recall_score, \n    classification_report\n)\n\n# ============================================\n# XGBOOST\n# ============================================\nfrom xgboost import XGBClassifier\n\n# ============================================\n# DEEP LEARNING & EMBEDDINGS\n# ============================================\nimport torch\nimport gensim.downloader as api\n\n# ============================================\n# DATASETS & DATA HANDLING\n# ============================================\nfrom datasets import load_dataset\n\n# ============================================\n# UTILITIES\n# ============================================\nimport requests\nimport json\nfrom time import sleep\nimport joblib\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T16:39:53.446417Z","iopub.execute_input":"2026-01-06T16:39:53.446954Z","iopub.status.idle":"2026-01-06T16:40:33.792778Z","shell.execute_reply.started":"2026-01-06T16:39:53.446922Z","shell.execute_reply":"2026-01-06T16:40:33.792043Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## perform datasets impoortation ","metadata":{}},{"cell_type":"code","source":"ds = load_dataset(\"lex_glue\", \"eurlex\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:03.538259Z","iopub.execute_input":"2026-01-05T03:20:03.538535Z","iopub.status.idle":"2026-01-05T03:20:18.416861Z","shell.execute_reply.started":"2026-01-05T03:20:03.538518Z","shell.execute_reply":"2026-01-05T03:20:18.416085Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"056b535c7e154df7a1d0e6fbce6e915b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"eurlex/train-00000-of-00001.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6d661c56c94a6bafd06c6279373af2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"eurlex/test-00000-of-00001.parquet:   0%|          | 0.00/24.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a61688e98d4c4cecb10dbebfcc09f720"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"eurlex/validation-00000-of-00001.parquet:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d79842dc44794c48b8ff3f9e108b0172"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/55000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba61f00ffaf54a26a7efa14eab7c6ff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a46b30a4d01496b845af0c8a7f56590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fedff0ced2c9454ab4fc176430182a3d"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(ds),print(type(ds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:18.418703Z","iopub.execute_input":"2026-01-05T03:20:18.419119Z","iopub.status.idle":"2026-01-05T03:20:18.425027Z","shell.execute_reply.started":"2026-01-05T03:20:18.419084Z","shell.execute_reply":"2026-01-05T03:20:18.424461Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels'],\n        num_rows: 55000\n    })\n    test: Dataset({\n        features: ['text', 'labels'],\n        num_rows: 5000\n    })\n    validation: Dataset({\n        features: ['text', 'labels'],\n        num_rows: 5000\n    })\n})\n<class 'datasets.dataset_dict.DatasetDict'>\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"ds['train']['text'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:18.425694Z","iopub.execute_input":"2026-01-05T03:20:18.425875Z","iopub.status.idle":"2026-01-05T03:20:18.443559Z","shell.execute_reply.started":"2026-01-05T03:20:18.425855Z","shell.execute_reply":"2026-01-05T03:20:18.442792Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'COUNCIL DECISION\\nof 7 June 2005\\nabrogating Decision 2005/136/EC on the existence of an excessive deficit in the Netherlands\\n(2005/729/EC)\\nTHE COUNCIL OF THE EUROPEAN UNION,\\nHaving regard to the Treaty establishing the European Community, and in particular Article 104(12) thereof,\\nHaving regard to the recommendation from the Commission,\\nWhereas:\\n(1)\\nBy Decision 2005/136/EC (1) following a recommendation from the Commission in accordance with Article 104(6) of the Treaty, the Council decided that an excessive deficit existed in the Netherlands.\\n(2)\\nIn accordance with Article 104(7) of the Treaty, the Council made a Recommendation on 2 June 2004 addressed to the Netherlands with a view to bringing the excessive deficit situation to an end. This Recommendation, in conjunction with Article 3(4) of Council Regulation (EC) No 1467/97 of 7 July 1997 on speeding up and clarifying the implementation of the excessive deficit procedure (2), established a deadline of 2005 at the latest for the correction of the excessive deficit.\\n(3)\\nIn accordance with Article 104(12) of the Treaty, a Council Decision on the existence of an excessive deficit is to be abrogated when the excessive deficit in the Member State concerned has, in the view of the Council, been corrected.\\n(4)\\nThe definitions of ‘government’ and ‘deficit’ are laid down in the Protocol on the excessive deficit procedure by reference to the European System of Integrated Economic Accounts, second edition. The data for the excessive deficit procedure are provided by the Commission.\\n(5)\\nBased on the data provided by the Commission after reporting by the Netherlands before 1 March 2005 in accordance with Council Regulation (EC) No 3605/93 of 22 November 1993 on the application of the Protocol on the excessive deficit procedure annexed to the Treaty establishing the European Community (3), on the subsequent reporting of revised general government accounts to Eurostat on 31 March 2005, and on the Commission services’ Spring 2005 forecast, the following conclusions are warranted:\\n-\\nthe general government deficit is estimated at 2,3 % of GDP in 2004, compared with 3,2 % in 2003. The outcome for 2004 is in compliance with the Council recommendation issued under Article 104(7) of the Treaty, particularly as regards the reduction of the government deficit below the reference value of 3 % of GDP by 2005 at the latest. Fiscal adjustment was pursued in 2004 in the form of substantial savings measures, partly contained in the 2004 budget and partly decided in the additional consolidation package on 14 April 2004. Moreover, stronger-than-expected tax receipts and additional revenues from the sale of natural gas in response to high oil prices helped reduce the deficit,\\n-\\nthe budgetary measures taken are geared towards securing a lasting improvement in the general government balance. For 2005, the Commission services’ Spring 2005 forecast projects a further decline in the general government deficit to 2,0 % of GDP, largely in response to savings measures, mostly of a structural nature, adding up to 0,5 % of GDP. This is in line with the official target of a deficit of 2,1 % of GDP. For 2006, the Commission services’ Spring 2005 forecast projects, based on currently known policies, a further fall in the deficit to 1,6 % of GDP, pointing to the durable correction of the budget deficit,\\n-\\nthe budgetary consolidation will be sustained through a reduction in the cyclically adjusted deficit which is expected to reach close to balance after the excessive deficit has been corrected. In 2004, the cyclically adjusted deficit fell markedly to 1,2 % of GDP, compared to 2,0 % of GDP in 2003. The Commission services’ Spring 2005 forecast projects the cyclically adjusted deficit to further decrease in 2005 by another 0,8 % of GDP, to 0,4 % of GDP, which is close to balance, and to fall to 0,0 % of GDP in 2006,\\n-\\naccording to the March 2005 excessive deficit procedure notification, the government debt ratio was kept below the 60 % of GDP reference value in 2004. The Commission services’ Spring 2004 forecast projects it to remain below this threshold in 2005 and 2006.\\n(6)\\nDecision 2005/136/EC should therefore be abrogated,\\nHAS ADOPTED THIS DECISION:\\nArticle 1\\nFrom an overall assessment it follows that the correction of the excessive deficit situation in the Netherlands was completed in 2004, under the terms of the recommendation addressed to the Netherlands on 2 June 2004 in accordance with Article 104(7) of the Treaty.\\nArticle 2\\nDecision 2005/136/EC is hereby abrogated.\\nArticle 3\\nThis Decision is addressed to the Kingdom of the Netherlands.\\nDone at Luxembourg, 7 June 2005.'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"label_info = ds[\"train\"].features[\"labels\"]\nlabel_names = label_info.feature.names\n\nprint(label_names[:20])   # print first 20 labels\nprint(len(label_names))   # number of labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:18.444360Z","iopub.execute_input":"2026-01-05T03:20:18.444699Z","iopub.status.idle":"2026-01-05T03:20:18.457706Z","shell.execute_reply.started":"2026-01-05T03:20:18.444676Z","shell.execute_reply":"2026-01-05T03:20:18.456958Z"}},"outputs":[{"name":"stdout","text":"['100163', '100168', '100169', '100170', '100171', '100172', '100173', '100174', '100175', '100176', '100177', '100179', '100180', '100183', '100184', '100185', '100186', '100187', '100189', '100190']\n100\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(\"Train size:\", len(ds[\"train\"]))\nprint(\"Validation size:\", len(ds[\"validation\"]))\nprint(\"Test size:\", len(ds[\"test\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:18.458492Z","iopub.execute_input":"2026-01-05T03:20:18.459066Z","iopub.status.idle":"2026-01-05T03:20:18.471355Z","shell.execute_reply.started":"2026-01-05T03:20:18.459048Z","shell.execute_reply":"2026-01-05T03:20:18.470649Z"}},"outputs":[{"name":"stdout","text":"Train size: 55000\nValidation size: 5000\nTest size: 5000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Get the int2str function from the ClassLabel feature\nid2label = ds[\"train\"].features[\"labels\"].feature.int2str\n\n# Loop over all labels\nfor i in range(len(ds[\"train\"].features[\"labels\"].feature.names)):\n    if i%10==0:\n        print(\"\\n\")\n    print(i, \"→\", id2label(i),end=\"||\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:18.472033Z","iopub.execute_input":"2026-01-05T03:20:18.472246Z","iopub.status.idle":"2026-01-05T03:20:18.487878Z","shell.execute_reply.started":"2026-01-05T03:20:18.472231Z","shell.execute_reply":"2026-01-05T03:20:18.487142Z"}},"outputs":[{"name":"stdout","text":"\n\n0 → 100163||1 → 100168||2 → 100169||3 → 100170||4 → 100171||5 → 100172||6 → 100173||7 → 100174||8 → 100175||9 → 100176||\n\n10 → 100177||11 → 100179||12 → 100180||13 → 100183||14 → 100184||15 → 100185||16 → 100186||17 → 100187||18 → 100189||19 → 100190||\n\n20 → 100191||21 → 100192||22 → 100193||23 → 100194||24 → 100195||25 → 100196||26 → 100197||27 → 100198||28 → 100199||29 → 100200||\n\n30 → 100201||31 → 100202||32 → 100204||33 → 100205||34 → 100206||35 → 100207||36 → 100212||37 → 100214||38 → 100215||39 → 100220||\n\n40 → 100221||41 → 100222||42 → 100223||43 → 100224||44 → 100226||45 → 100227||46 → 100229||47 → 100230||48 → 100231||49 → 100232||\n\n50 → 100233||51 → 100234||52 → 100235||53 → 100237||54 → 100238||55 → 100239||56 → 100240||57 → 100241||58 → 100242||59 → 100243||\n\n60 → 100244||61 → 100245||62 → 100246||63 → 100247||64 → 100248||65 → 100249||66 → 100250||67 → 100252||68 → 100253||69 → 100254||\n\n70 → 100255||71 → 100256||72 → 100257||73 → 100258||74 → 100259||75 → 100260||76 → 100261||77 → 100262||78 → 100263||79 → 100264||\n\n80 → 100265||81 → 100266||82 → 100268||83 → 100269||84 → 100270||85 → 100271||86 → 100272||87 → 100273||88 → 100274||89 → 100275||\n\n90 → 100276||91 → 100277||92 → 100278||93 → 100279||94 → 100280||95 → 100281||96 → 100282||97 → 100283||98 → 100284||99 → 100285||","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"label2name = ds[\"train\"].features[\"labels\"].feature.names\ndef get_eurovoc_label(concept_id):\n    \"\"\"Fetch label from EuroVoc SPARQL endpoint\"\"\"\n    sparql_endpoint = \"http://publications.europa.eu/webapi/rdf/sparql\"\n    \n    query = f\"\"\"\n    PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n    SELECT ?label\n    WHERE {{\n      <http://eurovoc.europa.eu/{concept_id}> skos:prefLabel ?label .\n      FILTER(lang(?label) = 'en')\n    }}\n    \"\"\"\n    \n    try:\n        response = requests.get(\n            sparql_endpoint,\n            params={'query': query, 'format': 'json'},\n            timeout=10\n        )\n        if response.status_code == 200:\n            data = response.json()\n            if data['results']['bindings']:\n                return data['results']['bindings'][0]['label']['value']\n    except Exception as e:\n        print(f\"Error for {concept_id}: {e}\")\n    \n    return concept_id\n\n# Build mapping with rate limiting\nlabel2description = {}\nfor i, concept_id in enumerate(label2name):\n    label2description[concept_id] = get_eurovoc_label(concept_id)\n    print(f\"{concept_id}: {label2description[concept_id]}\")\n    if i % 10 == 0:  # Add delay every 10 requests\n        sleep(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:18.488673Z","iopub.execute_input":"2026-01-05T03:20:18.488982Z","iopub.status.idle":"2026-01-05T03:20:54.401558Z","shell.execute_reply.started":"2026-01-05T03:20:18.488965Z","shell.execute_reply":"2026-01-05T03:20:54.400927Z"}},"outputs":[{"name":"stdout","text":"100163: 0406 political framework\n100168: 0431 politics and public safety\n100169: 0436 executive power and public service\n100170: 0806 international affairs\n100171: 0811 cooperation policy\n100172: 0816 international security\n100173: 0821 defence\n100174: 1006 EU institutions and European civil service\n100175: 1011 European Union law\n100176: 1016 European construction\n100177: 1021 EU finance\n100179: 1211 civil law\n100180: 1216 criminal law\n100183: 1231 international law\n100184: 1236 rights and freedoms\n100185: 1606 economic policy\n100186: 1611 economic conditions\n100187: 1616 regions and regional policy\n100189: 1626 national accounts\n100190: 1631 economic analysis\n100191: 2006 trade policy\n100192: 2011 tariff policy\n100193: 2016 trade\n100194: 2021 international trade\n100195: 2026 consumption\n100196: 2031 marketing\n100197: 2036 distributive trades\n100198: 2406 monetary relations\n100199: 2411 monetary economics\n100200: 2416 financial institutions and credit\n100201: 2421 free movement of capital\n100202: 2426 financing and investment\n100204: 2436 public finance and budget policy\n100205: 2441 budget\n100206: 2446 taxation\n100207: 2451 prices\n100212: 2826 social affairs\n100214: 2836 social protection\n100215: 2841 health\n100220: 3221 documentation\n100221: 3226 communications\n100222: 3231 information and information processing\n100223: 3236 information technology and data processing\n100224: 3606 natural and applied sciences\n100226: 4006 business organisation\n100227: 4011 business classification\n100229: 4021 management\n100230: 4026 accounting\n100231: 4031 competition\n100232: 4406 employment\n100233: 4411 labour market\n100234: 4416 organisation of work and working conditions\n100235: 4421 personnel management and staff remuneration\n100237: 4806 transport policy\n100238: 4811 organisation of transport\n100239: 4816 land transport\n100240: 4821 maritime and inland waterway transport\n100241: 4826 air and space transport\n100242: 5206 environmental policy\n100243: 5211 natural environment\n100244: 5216 deterioration of the environment\n100245: 5606 agricultural policy\n100246: 5611 agricultural structures and production\n100247: 5616 farming systems\n100248: 5621 cultivation of agricultural land\n100249: 5626 means of agricultural production\n100250: 5631 agricultural activity\n100252: 5641 fisheries\n100253: 6006 plant product\n100254: 6011 animal product\n100255: 6016 processed agricultural produce\n100256: 6021 beverages and sugar\n100257: 6026 foodstuff\n100258: 6031 agri-foodstuffs\n100259: 6036 food technology\n100260: 6406 production\n100261: 6411 technology and technical regulations\n100262: 6416 research and intellectual property\n100263: 6606 energy policy\n100264: 6611 coal and mining industries\n100265: 6616 oil industry\n100266: 6621 electrical and nuclear industries\n100268: 6806 industrial structures and policy\n100269: 6811 chemistry\n100270: 6816 iron, steel and other metal industries\n100271: 6821 mechanical engineering\n100272: 6826 electronics and electrical engineering\n100273: 6831 building and public works\n100274: 6836 wood industry\n100275: 6841 leather and textile industries\n100276: 6846 miscellaneous industries\n100277: 7206 Europe\n100278: 7211 regions of EU Member States\n100279: 7216 America\n100280: 7221 Africa\n100281: 7226 Asia and Oceania\n100282: 7231 economic geography\n100283: 7236 political geography\n100284: 7241 overseas countries and territories\n100285: 7606 United Nations\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"label2description,len(label2description)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.403807Z","iopub.execute_input":"2026-01-05T03:20:54.404082Z","iopub.status.idle":"2026-01-05T03:20:54.409790Z","shell.execute_reply.started":"2026-01-05T03:20:54.404065Z","shell.execute_reply":"2026-01-05T03:20:54.409235Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"({'100163': '0406 political framework',\n  '100168': '0431 politics and public safety',\n  '100169': '0436 executive power and public service',\n  '100170': '0806 international affairs',\n  '100171': '0811 cooperation policy',\n  '100172': '0816 international security',\n  '100173': '0821 defence',\n  '100174': '1006 EU institutions and European civil service',\n  '100175': '1011 European Union law',\n  '100176': '1016 European construction',\n  '100177': '1021 EU finance',\n  '100179': '1211 civil law',\n  '100180': '1216 criminal law',\n  '100183': '1231 international law',\n  '100184': '1236 rights and freedoms',\n  '100185': '1606 economic policy',\n  '100186': '1611 economic conditions',\n  '100187': '1616 regions and regional policy',\n  '100189': '1626 national accounts',\n  '100190': '1631 economic analysis',\n  '100191': '2006 trade policy',\n  '100192': '2011 tariff policy',\n  '100193': '2016 trade',\n  '100194': '2021 international trade',\n  '100195': '2026 consumption',\n  '100196': '2031 marketing',\n  '100197': '2036 distributive trades',\n  '100198': '2406 monetary relations',\n  '100199': '2411 monetary economics',\n  '100200': '2416 financial institutions and credit',\n  '100201': '2421 free movement of capital',\n  '100202': '2426 financing and investment',\n  '100204': '2436 public finance and budget policy',\n  '100205': '2441 budget',\n  '100206': '2446 taxation',\n  '100207': '2451 prices',\n  '100212': '2826 social affairs',\n  '100214': '2836 social protection',\n  '100215': '2841 health',\n  '100220': '3221 documentation',\n  '100221': '3226 communications',\n  '100222': '3231 information and information processing',\n  '100223': '3236 information technology and data processing',\n  '100224': '3606 natural and applied sciences',\n  '100226': '4006 business organisation',\n  '100227': '4011 business classification',\n  '100229': '4021 management',\n  '100230': '4026 accounting',\n  '100231': '4031 competition',\n  '100232': '4406 employment',\n  '100233': '4411 labour market',\n  '100234': '4416 organisation of work and working conditions',\n  '100235': '4421 personnel management and staff remuneration',\n  '100237': '4806 transport policy',\n  '100238': '4811 organisation of transport',\n  '100239': '4816 land transport',\n  '100240': '4821 maritime and inland waterway transport',\n  '100241': '4826 air and space transport',\n  '100242': '5206 environmental policy',\n  '100243': '5211 natural environment',\n  '100244': '5216 deterioration of the environment',\n  '100245': '5606 agricultural policy',\n  '100246': '5611 agricultural structures and production',\n  '100247': '5616 farming systems',\n  '100248': '5621 cultivation of agricultural land',\n  '100249': '5626 means of agricultural production',\n  '100250': '5631 agricultural activity',\n  '100252': '5641 fisheries',\n  '100253': '6006 plant product',\n  '100254': '6011 animal product',\n  '100255': '6016 processed agricultural produce',\n  '100256': '6021 beverages and sugar',\n  '100257': '6026 foodstuff',\n  '100258': '6031 agri-foodstuffs',\n  '100259': '6036 food technology',\n  '100260': '6406 production',\n  '100261': '6411 technology and technical regulations',\n  '100262': '6416 research and intellectual property',\n  '100263': '6606 energy policy',\n  '100264': '6611 coal and mining industries',\n  '100265': '6616 oil industry',\n  '100266': '6621 electrical and nuclear industries',\n  '100268': '6806 industrial structures and policy',\n  '100269': '6811 chemistry',\n  '100270': '6816 iron, steel and other metal industries',\n  '100271': '6821 mechanical engineering',\n  '100272': '6826 electronics and electrical engineering',\n  '100273': '6831 building and public works',\n  '100274': '6836 wood industry',\n  '100275': '6841 leather and textile industries',\n  '100276': '6846 miscellaneous industries',\n  '100277': '7206 Europe',\n  '100278': '7211 regions of EU Member States',\n  '100279': '7216 America',\n  '100280': '7221 Africa',\n  '100281': '7226 Asia and Oceania',\n  '100282': '7231 economic geography',\n  '100283': '7236 political geography',\n  '100284': '7241 overseas countries and territories',\n  '100285': '7606 United Nations'},\n 100)"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# High-level category aggregation for EuroVoc classes\nhigh_level_categories = {\n    \"Politics & Government\": {\n        \"100163\", \"100168\", \"100169\", \"100174\", \"100175\", \"100176\", \"100177\"\n    },\n    \n    \"International Affairs & Defense\": {\n        \"100170\", \"100171\", \"100172\", \"100173\", \"100183\", \"100285\"\n    },\n    \n    \"Law & Justice\": {\n        \"100179\", \"100180\", \"100184\"\n    },\n    \n    \"Economics & Finance\": {\n        \"100185\", \"100186\", \"100189\", \"100190\", \"100198\", \"100199\", \"100200\", \n        \"100201\", \"100202\", \"100204\", \"100205\", \"100206\", \"100207\"\n    },\n    \n    \"Trade & Business\": {\n        \"100191\", \"100192\", \"100193\", \"100194\", \"100195\", \"100196\", \"100197\",\n        \"100226\", \"100227\", \"100229\", \"100230\", \"100231\"\n    },\n    \n    \"Employment & Labor\": {\n        \"100232\", \"100233\", \"100234\", \"100235\"\n    },\n    \n    \"Social Affairs & Health\": {\n        \"100212\", \"100214\", \"100215\"\n    },\n    \n    \"Technology & Science\": {\n        \"100220\", \"100221\", \"100222\", \"100223\", \"100224\", \"100261\", \"100262\"\n    },\n    \n    \"Transportation\": {\n        \"100237\", \"100238\", \"100239\", \"100240\", \"100241\"\n    },\n    \n    \"Environment\": {\n        \"100242\", \"100243\", \"100244\"\n    },\n    \n    \"Agriculture & Food\": {\n        \"100245\", \"100246\", \"100247\", \"100248\", \"100249\", \"100250\", \"100252\",\n        \"100253\", \"100254\", \"100255\", \"100256\", \"100257\", \"100258\", \"100259\"\n    },\n    \n    \"Energy & Resources\": {\n        \"100263\", \"100264\", \"100265\", \"100266\"\n    },\n    \n    \"Industry & Manufacturing\": {\n        \"100260\", \"100268\", \"100269\", \"100270\", \"100271\", \"100272\", \"100273\",\n        \"100274\", \"100275\", \"100276\"\n    },\n    \n    \"Geography & Regional\": {\n        \"100187\", \"100277\", \"100278\", \"100279\", \"100280\", \"100281\", \"100282\",\n        \"100283\", \"100284\"\n    },\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.410471Z","iopub.execute_input":"2026-01-05T03:20:54.410735Z","iopub.status.idle":"2026-01-05T03:20:54.428548Z","shell.execute_reply.started":"2026-01-05T03:20:54.410715Z","shell.execute_reply":"2026-01-05T03:20:54.427826Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"ds[\"train\"][\"labels\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.429227Z","iopub.execute_input":"2026-01-05T03:20:54.429509Z","iopub.status.idle":"2026-01-05T03:20:54.448587Z","shell.execute_reply.started":"2026-01-05T03:20:54.429486Z","shell.execute_reply":"2026-01-05T03:20:54.447843Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Column([[28, 32, 33, 91, 96, 97], [4, 21, 23, 68], [9, 15, 16, 39], [20, 28, 61, 62], [20, 71, 72]])"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"id_code_mapping={\n    i: id2label(i) for i in range(100)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.449469Z","iopub.execute_input":"2026-01-05T03:20:54.449714Z","iopub.status.idle":"2026-01-05T03:20:54.459992Z","shell.execute_reply.started":"2026-01-05T03:20:54.449698Z","shell.execute_reply":"2026-01-05T03:20:54.459401Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"categories_id={\n    key:i for i,key in enumerate(high_level_categories.keys())\n}\ncategories_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.460657Z","iopub.execute_input":"2026-01-05T03:20:54.460839Z","iopub.status.idle":"2026-01-05T03:20:54.474971Z","shell.execute_reply.started":"2026-01-05T03:20:54.460826Z","shell.execute_reply":"2026-01-05T03:20:54.474262Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'Politics & Government': 0,\n 'International Affairs & Defense': 1,\n 'Law & Justice': 2,\n 'Economics & Finance': 3,\n 'Trade & Business': 4,\n 'Employment & Labor': 5,\n 'Social Affairs & Health': 6,\n 'Technology & Science': 7,\n 'Transportation': 8,\n 'Environment': 9,\n 'Agriculture & Food': 10,\n 'Energy & Resources': 11,\n 'Industry & Manufacturing': 12,\n 'Geography & Regional': 13}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"X_train ,X_test,X_val= ds[\"train\"][\"text\"], ds[\"test\"][\"text\"], ds[\"validation\"][\"text\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.475727Z","iopub.execute_input":"2026-01-05T03:20:54.476052Z","iopub.status.idle":"2026-01-05T03:20:54.489202Z","shell.execute_reply.started":"2026-01-05T03:20:54.476031Z","shell.execute_reply":"2026-01-05T03:20:54.488423Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#lower casing \n#limmitization \n#stop word \n#remove urls,gmails,...\n#.............","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.489949Z","iopub.execute_input":"2026-01-05T03:20:54.490145Z","iopub.status.idle":"2026-01-05T03:20:54.546533Z","shell.execute_reply.started":"2026-01-05T03:20:54.490129Z","shell.execute_reply":"2026-01-05T03:20:54.545801Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"y_train ,y_test ,y_val= ds[\"train\"][\"labels\"], ds[\"test\"][\"labels\"], ds[\"validation\"][\"labels\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.547337Z","iopub.execute_input":"2026-01-05T03:20:54.547592Z","iopub.status.idle":"2026-01-05T03:20:54.561253Z","shell.execute_reply.started":"2026-01-05T03:20:54.547566Z","shell.execute_reply":"2026-01-05T03:20:54.560660Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def check_category_name(id_,high_level_categories=high_level_categories,id_code_mapping=id_code_mapping):\n    for key in high_level_categories.keys():\n        if id_code_mapping[id_] in high_level_categories.get(key):\n            return key\n\ndef generate_new_label(y):\n    new_y=[]\n    for target in y:\n        new_target=[categories_id[check_category_name(t)] for t in target]\n        new_target_unique=list(set(new_target))\n        new_y.append(new_target_unique)\n    return new_y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.562041Z","iopub.execute_input":"2026-01-05T03:20:54.562310Z","iopub.status.idle":"2026-01-05T03:20:54.575446Z","shell.execute_reply.started":"2026-01-05T03:20:54.562295Z","shell.execute_reply":"2026-01-05T03:20:54.574874Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"y_train_h = generate_new_label(y_train)\ny_test_h = generate_new_label(y_test)\ny_val_h = generate_new_label(y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:54.576142Z","iopub.execute_input":"2026-01-05T03:20:54.576391Z","iopub.status.idle":"2026-01-05T03:20:56.056932Z","shell.execute_reply.started":"2026-01-05T03:20:54.576370Z","shell.execute_reply":"2026-01-05T03:20:56.056349Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"#label representation \ndef label_to_fixed_vector(labels):\n    mlb = MultiLabelBinarizer(classes=range(0, 14))  # specify 0–99 classes\n    Y = mlb.fit_transform(labels)\n    \n    return Y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:56.057672Z","iopub.execute_input":"2026-01-05T03:20:56.057929Z","iopub.status.idle":"2026-01-05T03:20:56.388856Z","shell.execute_reply.started":"2026-01-05T03:20:56.057905Z","shell.execute_reply":"2026-01-05T03:20:56.388278Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"fixed_size_y_train ,fixed_size_y_test ,fixed_size_y_val= label_to_fixed_vector(y_train_h),label_to_fixed_vector(y_test_h),label_to_fixed_vector(y_val_h)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:56.389542Z","iopub.execute_input":"2026-01-05T03:20:56.390008Z","iopub.status.idle":"2026-01-05T03:20:56.457778Z","shell.execute_reply.started":"2026-01-05T03:20:56.389984Z","shell.execute_reply":"2026-01-05T03:20:56.457052Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"label_freq = fixed_size_y_train.mean(axis=0)   # (14,)\nlabel_weights = 1 / (label_freq + 1e-6)\n\nsample_weights = (fixed_size_y_train * label_weights).sum(axis=1)\nsample_weights = sample_weights / sample_weights.mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:56.458609Z","iopub.execute_input":"2026-01-05T03:20:56.458857Z","iopub.status.idle":"2026-01-05T03:20:56.483495Z","shell.execute_reply.started":"2026-01-05T03:20:56.458836Z","shell.execute_reply":"2026-01-05T03:20:56.482715Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"tfidf = TfidfVectorizer(\n    max_features=50000,      \n    ngram_range=(1,2),        \n    min_df=2,                 \n    stop_words=\"english\"      \n)\n\nvectorized_X_train = tfidf.fit_transform(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:20:56.484354Z","iopub.execute_input":"2026-01-05T03:20:56.484612Z","iopub.status.idle":"2026-01-05T03:22:23.074723Z","shell.execute_reply.started":"2026-01-05T03:20:56.484591Z","shell.execute_reply":"2026-01-05T03:22:23.073989Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"vectorized_X_test  = tfidf.transform(X_test)\nvectorized_X_val  = tfidf.transform(X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:22:23.075530Z","iopub.execute_input":"2026-01-05T03:22:23.075756Z","iopub.status.idle":"2026-01-05T03:22:38.675565Z","shell.execute_reply.started":"2026-01-05T03:22:23.075731Z","shell.execute_reply":"2026-01-05T03:22:38.674962Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"vectorized_X_val.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:22:38.676259Z","iopub.execute_input":"2026-01-05T03:22:38.676458Z","iopub.status.idle":"2026-01-05T03:22:38.681406Z","shell.execute_reply.started":"2026-01-05T03:22:38.676442Z","shell.execute_reply":"2026-01-05T03:22:38.680682Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(5000, 50000)"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# Reduce 50,000 sparse features to 300 dense features\nsvd = TruncatedSVD(n_components=300, random_state=42)\nX_train_svd = svd.fit_transform(vectorized_X_train)\nX_test_svd = svd.transform(vectorized_X_test)\nX_val_svd = svd.transform(vectorized_X_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:22:38.682239Z","iopub.execute_input":"2026-01-05T03:22:38.682488Z","iopub.status.idle":"2026-01-05T03:24:00.405976Z","shell.execute_reply.started":"2026-01-05T03:22:38.682466Z","shell.execute_reply":"2026-01-05T03:24:00.405347Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## XGBoost Model","metadata":{}},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=500,\n    max_depth=15,\n    learning_rate=0.1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective=\"binary:logistic\",\n    \n    # --- GPU Acceleration ---\n    tree_method=\"hist\",\n    device=\"cuda\",\n    \n    # --- REGULARIZATION TERMS ---\n    reg_alpha=10,       \n    reg_lambda=10,      \n    gamma=0.2,           \n    min_child_weight=2,  \n    \n    random_state=42\n)\n\n#model = ClassifierChain(base_model, order='random', random_state=42)\nmodel.fit(X_train_svd, fixed_size_y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:24:00.406716Z","iopub.execute_input":"2026-01-05T03:24:00.406922Z","iopub.status.idle":"2026-01-05T03:25:15.861418Z","shell.execute_reply.started":"2026-01-05T03:24:00.406905Z","shell.execute_reply":"2026-01-05T03:25:15.860745Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device='cuda', early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=0.2, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=15, max_leaves=None,\n              min_child_weight=2, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=500, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=0.2, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=15, max_leaves=None,\n              min_child_weight=2, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=500, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=0.2, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=15, max_leaves=None,\n              min_child_weight=2, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=500, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def evaluate_set(model, X_data, y_true, dataset_name, category_names=None):\n    \"\"\"\n    Evaluates the model and prints detailed metrics for the given dataset.\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"📊 {dataset_name.upper()} SET EVALUATION\")\n    print(f\"{'='*60}\")\n    \n    # 1. Generate Predictions\n    print(f\"Generating predictions for {dataset_name}...\")\n    y_pred = model.predict(X_data)\n    print(\"Predictions complete!\")\n    \n    # 2. Calculate Overall Metrics\n    subset_acc = accuracy_score(y_true, y_pred)\n    h_loss = hamming_loss(y_true, y_pred)\n    micro_f1 = f1_score(y_true, y_pred, average='micro')\n    macro_f1 = f1_score(y_true, y_pred, average='macro')\n    weighted_f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    print(f\"\\n--- Overall Metrics ---\")\n    print(f\"Subset Accuracy:     {subset_acc:.4f}\")\n    print(f\"Hamming Loss:        {h_loss:.4f}\")\n    print(f\"Micro F1 Score:      {micro_f1:.4f}\")\n    print(f\"Macro F1 Score:      {macro_f1:.4f}\")\n\n    # 3. Per-Label Breakdown (Now enabled for ALL sets if names are provided)\n    if category_names:\n        print(f\"\\n--- Per-Label F1 Scores ({dataset_name}) ---\")\n        per_label_f1 = f1_score(y_true, y_pred, average=None)\n        \n        # Header for the table\n        print(f\"{'Category':<40} | {'F1 Score'}\")\n        print(\"-\" * 55)\n        \n        for category, f1 in zip(category_names, per_label_f1):\n            # Highlight weak classes in RED (if supported) or with a marker\n            marker = \"⚠️\" if f1 < 0.5 else \" \"\n            print(f\"{category:<40} | {f1:.4f} {marker}\")\n            \n    # Return metrics for the final diagnosis\n    metrics = {\n        \"micro_f1\": micro_f1,\n        \"macro_f1\": macro_f1,\n        \"per_label_f1\": per_label_f1 if category_names else None\n    }\n    return y_pred, metrics\n\ndef print_final_diagnosis(train_metrics, val_metrics, test_metrics, category_names):\n    \"\"\"\n    Compares Train vs Test to give specific advice per class.\n    \"\"\"\n    print(f\"\\n{'#'*60}\")\n    print(f\"🏥 AUTOMATED MODEL DIAGNOSIS\")\n    print(f\"{'#'*60}\")\n    \n    # 1. Generalization Gap\n    gap = train_metrics['micro_f1'] - test_metrics['micro_f1']\n    print(f\"📉 Overall Overfitting Gap: {gap:.4f}\")\n    \n    if gap > 0.10:\n        print(\"⚠️  High Overfitting detected overall.\")\n    else:\n        print(\"✅  Good Generalization overall.\")\n\n    # 2. Per-Class Overfitting Analysis\n    print(f\"\\n🔍 Detailed Class Analysis (Train vs Test F1):\")\n    print(f\"{'Category':<40} | {'Train':<7} | {'Test':<7} | {'Gap'}\")\n    print(\"-\" * 75)\n    \n    train_scores = train_metrics['per_label_f1']\n    test_scores = test_metrics['per_label_f1']\n    \n    for i, cat in enumerate(category_names):\n        t_score = train_scores[i]\n        v_score = test_scores[i]\n        diff = t_score - v_score\n        \n        # Flag problematic classes\n        status = \"\"\n        if v_score < 0.4: status = \"❌ POOR\"\n        elif diff > 0.2:  status = \"⚠️ OVERFIT\"\n        \n        print(f\"{cat:<40} | {t_score:.4f}  | {v_score:.4f}  | {diff:+.4f} {status}\")\n\n# ============================================\n# EXECUTE EVALUATION\n# ============================================\n\n# Ensure category names are sorted by ID (0..13)\nsorted_categories = sorted(categories_id.keys(), key=lambda k: categories_id[k])\n\n# 1. Evaluate Train (Pass sorted_categories to see per-class scores)\n_, train_metrics = evaluate_set(model, X_train_svd, fixed_size_y_train, \"Train\", sorted_categories)\n\n# 2. Evaluate Validation\n_, val_metrics = evaluate_set(model, X_val_svd, fixed_size_y_val, \"Validation\", sorted_categories)\n\n# 3. Evaluate Test\n_, test_metrics = evaluate_set(model, X_test_svd, fixed_size_y_test, \"Test\", sorted_categories)\n\n# 4. Final Comparison\nprint_final_diagnosis(train_metrics, val_metrics, test_metrics, sorted_categories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:25:15.864555Z","iopub.execute_input":"2026-01-05T03:25:15.865088Z","iopub.status.idle":"2026-01-05T03:25:19.254840Z","shell.execute_reply.started":"2026-01-05T03:25:15.865069Z","shell.execute_reply":"2026-01-05T03:25:19.254153Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\n📊 TRAIN SET EVALUATION\n============================================================\nGenerating predictions for Train...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [03:25:15] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Predictions complete!\n\n--- Overall Metrics ---\nSubset Accuracy:     0.9767\nHamming Loss:        0.0019\nMicro F1 Score:      0.9956\nMacro F1 Score:      0.9869\n\n--- Per-Label F1 Scores (Train) ---\nCategory                                 | F1 Score\n-------------------------------------------------------\nPolitics & Government                    | 0.9961  \nInternational Affairs & Defense          | 0.9944  \nLaw & Justice                            | 0.9602  \nEconomics & Finance                      | 0.9965  \nTrade & Business                         | 0.9980  \nEmployment & Labor                       | 0.9766  \nSocial Affairs & Health                  | 0.9917  \nTechnology & Science                     | 0.9937  \nTransportation                           | 0.9838  \nEnvironment                              | 0.9840  \nAgriculture & Food                       | 0.9985  \nEnergy & Resources                       | 0.9520  \nIndustry & Manufacturing                 | 0.9941  \nGeography & Regional                     | 0.9975  \n\n============================================================\n📊 VALIDATION SET EVALUATION\n============================================================\nGenerating predictions for Validation...\nPredictions complete!\n\n--- Overall Metrics ---\nSubset Accuracy:     0.3592\nHamming Loss:        0.0847\nMicro F1 Score:      0.8030\nMacro F1 Score:      0.6885\n\n--- Per-Label F1 Scores (Validation) ---\nCategory                                 | F1 Score\n-------------------------------------------------------\nPolitics & Government                    | 0.7610  \nInternational Affairs & Defense          | 0.7464  \nLaw & Justice                            | 0.3742 ⚠️\nEconomics & Finance                      | 0.7275  \nTrade & Business                         | 0.8522  \nEmployment & Labor                       | 0.5986  \nSocial Affairs & Health                  | 0.7083  \nTechnology & Science                     | 0.6339  \nTransportation                           | 0.8073  \nEnvironment                              | 0.4890 ⚠️\nAgriculture & Food                       | 0.9762  \nEnergy & Resources                       | 0.4878 ⚠️\nIndustry & Manufacturing                 | 0.5857  \nGeography & Regional                     | 0.8909  \n\n============================================================\n📊 TEST SET EVALUATION\n============================================================\nGenerating predictions for Test...\nPredictions complete!\n\n--- Overall Metrics ---\nSubset Accuracy:     0.2508\nHamming Loss:        0.1022\nMicro F1 Score:      0.7559\nMacro F1 Score:      0.6399\n\n--- Per-Label F1 Scores (Test) ---\nCategory                                 | F1 Score\n-------------------------------------------------------\nPolitics & Government                    | 0.7153  \nInternational Affairs & Defense          | 0.7576  \nLaw & Justice                            | 0.3406 ⚠️\nEconomics & Finance                      | 0.5515  \nTrade & Business                         | 0.7853  \nEmployment & Labor                       | 0.3804 ⚠️\nSocial Affairs & Health                  | 0.6346  \nTechnology & Science                     | 0.6793  \nTransportation                           | 0.7654  \nEnvironment                              | 0.4898 ⚠️\nAgriculture & Food                       | 0.9616  \nEnergy & Resources                       | 0.4762 ⚠️\nIndustry & Manufacturing                 | 0.5461  \nGeography & Regional                     | 0.8749  \n\n############################################################\n🏥 AUTOMATED MODEL DIAGNOSIS\n############################################################\n📉 Overall Overfitting Gap: 0.2397\n⚠️  High Overfitting detected overall.\n\n🔍 Detailed Class Analysis (Train vs Test F1):\nCategory                                 | Train   | Test    | Gap\n---------------------------------------------------------------------------\nPolitics & Government                    | 0.9961  | 0.7153  | +0.2808 ⚠️ OVERFIT\nInternational Affairs & Defense          | 0.9944  | 0.7576  | +0.2368 ⚠️ OVERFIT\nLaw & Justice                            | 0.9602  | 0.3406  | +0.6196 ❌ POOR\nEconomics & Finance                      | 0.9965  | 0.5515  | +0.4451 ⚠️ OVERFIT\nTrade & Business                         | 0.9980  | 0.7853  | +0.2128 ⚠️ OVERFIT\nEmployment & Labor                       | 0.9766  | 0.3804  | +0.5962 ❌ POOR\nSocial Affairs & Health                  | 0.9917  | 0.6346  | +0.3571 ⚠️ OVERFIT\nTechnology & Science                     | 0.9937  | 0.6793  | +0.3144 ⚠️ OVERFIT\nTransportation                           | 0.9838  | 0.7654  | +0.2184 ⚠️ OVERFIT\nEnvironment                              | 0.9840  | 0.4898  | +0.4942 ⚠️ OVERFIT\nAgriculture & Food                       | 0.9985  | 0.9616  | +0.0369 \nEnergy & Resources                       | 0.9520  | 0.4762  | +0.4758 ⚠️ OVERFIT\nIndustry & Manufacturing                 | 0.9941  | 0.5461  | +0.4480 ⚠️ OVERFIT\nGeography & Regional                     | 0.9975  | 0.8749  | +0.1226 \n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# 1. Calculate Support (Instance Count) for each class per split\ntrain_support = fixed_size_y_train.sum(axis=0)\nval_support = fixed_size_y_val.sum(axis=0)\ntest_support = fixed_size_y_test.sum(axis=0)\n\n# 2. Retrieve F1 Scores (Assuming metrics were captured in previous step)\ntrain_f1 = train_metrics['per_label_f1']\nval_f1 = val_metrics['per_label_f1']\ntest_f1 = test_metrics['per_label_f1']\n\n# 3. Create a Consolidated DataFrame\ndf_comparison = pd.DataFrame({\n    'Category': sorted_categories,\n    \n    # Train Data\n    'Train_Count': train_support.astype(int),\n    'Train_F1': train_f1,\n    \n    # Validation Data\n    'Val_Count': val_support.astype(int),\n    'Val_F1': val_f1,\n    \n    # Test Data\n    'Test_Count': test_support.astype(int),\n    'Test_F1': test_f1\n})\n\n# 4. Calculate Percentage Representation \ntotal_train = fixed_size_y_train.shape[0]\ndf_comparison['Train_Freq_%'] = (df_comparison['Train_Count'] / total_train) * 100\n\n# Reorder columns for readability\ncols = ['Category', 'Train_Freq_%', \n        'Train_Count', 'Train_F1', \n        'Val_Count', 'Val_F1', \n        'Test_Count', 'Test_F1']\ndf_comparison = df_comparison[cols]\n\n# 5. Display the DataFrame sorted by Test Count \nprint(\"\\n\" + \"=\"*80)\nprint(\"📊 CLASS FREQUENCY vs. PERFORMANCE ANALYSIS\")\nprint(\"=\"*80)\nprint(df_comparison.sort_values(by='Test_Count', ascending=False).to_string(index=False, float_format=\"%.4f\"))\n\n# 6. Statistical Correlation Analysis\nprint(\"\\n\" + \"=\"*80)\nprint(\"📉 CORRELATION ANALYSIS (Count vs. F1 Score)\")\nprint(\"=\"*80)\ncorr_train = df_comparison['Train_Count'].corr(df_comparison['Train_F1'])\ncorr_val = df_comparison['Val_Count'].corr(df_comparison['Val_F1'])\ncorr_test = df_comparison['Test_Count'].corr(df_comparison['Test_F1'])\n\nprint(f\"Correlation (Train): {corr_train:.4f}  (High +ve means frequent classes score better)\")\nprint(f\"Correlation (Val):   {corr_val:.4f}\")\nprint(f\"Correlation (Test):  {corr_test:.4f}\")\n\nif corr_test > 0.5:\n    print(\"⚠️  STRONG BIAS: The model significantly favors frequent classes.\")\nelif corr_test > 0.2:\n    print(\"⚠️  MODERATE BIAS: Frequent classes tend to perform better.\")\nelse:\n    print(\"✅  LOW BIAS: The model handles rare classes relatively well.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:25:19.255570Z","iopub.execute_input":"2026-01-05T03:25:19.255819Z","iopub.status.idle":"2026-01-05T03:25:19.478429Z","shell.execute_reply.started":"2026-01-05T03:25:19.255791Z","shell.execute_reply":"2026-01-05T03:25:19.477584Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\n📊 CLASS FREQUENCY vs. PERFORMANCE ANALYSIS\n================================================================================\n                       Category  Train_Freq_%  Train_Count  Train_F1  Val_Count  Val_F1  Test_Count  Test_F1\n               Trade & Business       60.9800        33539    0.9980       2924  0.8522        2994   0.7853\n             Agriculture & Food       67.7364        37255    0.9985       2958  0.9762        2513   0.9616\n           Geography & Regional       42.4473        23346    0.9975       2105  0.8909        2260   0.8749\n          Politics & Government       26.3255        14479    0.9961       1726  0.7610        1516   0.7153\nInternational Affairs & Defense       16.6636         9165    0.9944       1163  0.7464        1315   0.7576\n            Economics & Finance       25.8200        14201    0.9965       1530  0.7275        1221   0.5515\n           Technology & Science       12.8618         7074    0.9937        809  0.6339         935   0.6793\n       Industry & Manufacturing       12.4436         6844    0.9941        644  0.5857         702   0.5461\n        Social Affairs & Health       10.3091         5670    0.9917        668  0.7083         683   0.6346\n                    Environment        5.6436         3104    0.9840        513  0.4890         609   0.4898\n                 Transportation        6.0127         3307    0.9838        511  0.8073         603   0.7654\n                  Law & Justice        2.3964         1318    0.9602        283  0.3742         243   0.3406\n             Energy & Resources        2.0018         1101    0.9520        149  0.4878         170   0.4762\n             Employment & Labor        3.3709         1854    0.9766        195  0.5986         155   0.3804\n\n================================================================================\n📉 CORRELATION ANALYSIS (Count vs. F1 Score)\n================================================================================\nCorrelation (Train): 0.6203  (High +ve means frequent classes score better)\nCorrelation (Val):   0.8199\nCorrelation (Test):  0.8137\n⚠️  STRONG BIAS: The model significantly favors frequent classes.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## First approach to address the imbalanced data issue: Class weighting ","metadata":{}},{"cell_type":"code","source":"# Calculate weight for each label: Total / (Num_Classes * Count)\nlabel_counts = fixed_size_y_train.sum(axis=0)\nclass_weights = len(fixed_size_y_train) / (len(label_counts) * label_counts)\n\n# Assign the highest weight of any label present in the sample\n# If a doc has \"Politics\" (freq) and \"Labor\" (rare), it gets the \"Labor\" weight.\nsample_weights = []\nfor row in fixed_size_y_train:\n    indices = np.where(row == 1)[0]\n    if len(indices) > 0:\n        weight = np.max(class_weights[indices]) # Weight by the rarest label in the doc\n    else:\n        weight = 1.0\n    sample_weights.append(weight)\n\n# Fit with weights\nmodel.fit(X_train_svd, fixed_size_y_train, sample_weight=sample_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:25:19.479285Z","iopub.execute_input":"2026-01-05T03:25:19.479860Z","iopub.status.idle":"2026-01-05T03:26:26.004958Z","shell.execute_reply.started":"2026-01-05T03:25:19.479833Z","shell.execute_reply":"2026-01-05T03:26:26.004223Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device='cuda', early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=0.2, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=15, max_leaves=None,\n              min_child_weight=2, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=500, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=0.2, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=15, max_leaves=None,\n              min_child_weight=2, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=500, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=0.2, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=15, max_leaves=None,\n              min_child_weight=2, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=500, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"\n# Ensure category names are sorted by ID (0..13)\nsorted_categories = sorted(categories_id.keys(), key=lambda k: categories_id[k])\n\n# 1. Evaluate Train (Pass sorted_categories to see per-class scores)\n_, train_metrics = evaluate_set(model, X_train_svd, fixed_size_y_train, \"Train\", sorted_categories)\n\n# 2. Evaluate Validation\n_, val_metrics = evaluate_set(model, X_val_svd, fixed_size_y_val, \"Validation\", sorted_categories)\n\n# 3. Evaluate Test\n_, test_metrics = evaluate_set(model, X_test_svd, fixed_size_y_test, \"Test\", sorted_categories)\n\n# 4. Final Comparison\nprint_final_diagnosis(train_metrics, val_metrics, test_metrics, sorted_categories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:26:26.005760Z","iopub.execute_input":"2026-01-05T03:26:26.005965Z","iopub.status.idle":"2026-01-05T03:26:29.168208Z","shell.execute_reply.started":"2026-01-05T03:26:26.005948Z","shell.execute_reply":"2026-01-05T03:26:29.167547Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\n📊 TRAIN SET EVALUATION\n============================================================\nGenerating predictions for Train...\nPredictions complete!\n\n--- Overall Metrics ---\nSubset Accuracy:     0.8312\nHamming Loss:        0.0144\nMicro F1 Score:      0.9659\nMacro F1 Score:      0.9613\n\n--- Per-Label F1 Scores (Train) ---\nCategory                                 | F1 Score\n-------------------------------------------------------\nPolitics & Government                    | 0.9475  \nInternational Affairs & Defense          | 0.9345  \nLaw & Justice                            | 0.9620  \nEconomics & Finance                      | 0.9449  \nTrade & Business                         | 0.9790  \nEmployment & Labor                       | 0.9722  \nSocial Affairs & Health                  | 0.9378  \nTechnology & Science                     | 0.9569  \nTransportation                           | 0.9713  \nEnvironment                              | 0.9756  \nAgriculture & Food                       | 0.9860  \nEnergy & Resources                       | 0.9800  \nIndustry & Manufacturing                 | 0.9471  \nGeography & Regional                     | 0.9633  \n\n============================================================\n📊 VALIDATION SET EVALUATION\n============================================================\nGenerating predictions for Validation...\nPredictions complete!\n\n--- Overall Metrics ---\nSubset Accuracy:     0.3896\nHamming Loss:        0.0775\nMicro F1 Score:      0.8232\nMacro F1 Score:      0.7092\n\n--- Per-Label F1 Scores (Validation) ---\nCategory                                 | F1 Score\n-------------------------------------------------------\nPolitics & Government                    | 0.7868  \nInternational Affairs & Defense          | 0.7611  \nLaw & Justice                            | 0.4991 ⚠️\nEconomics & Finance                      | 0.8192  \nTrade & Business                         | 0.9005  \nEmployment & Labor                       | 0.5996  \nSocial Affairs & Health                  | 0.7057  \nTechnology & Science                     | 0.6595  \nTransportation                           | 0.7574  \nEnvironment                              | 0.4982 ⚠️\nAgriculture & Food                       | 0.9741  \nEnergy & Resources                       | 0.4902 ⚠️\nIndustry & Manufacturing                 | 0.5860  \nGeography & Regional                     | 0.8909  \n\n============================================================\n📊 TEST SET EVALUATION\n============================================================\nGenerating predictions for Test...\nPredictions complete!\n\n--- Overall Metrics ---\nSubset Accuracy:     0.2840\nHamming Loss:        0.0908\nMicro F1 Score:      0.7887\nMacro F1 Score:      0.6790\n\n--- Per-Label F1 Scores (Test) ---\nCategory                                 | F1 Score\n-------------------------------------------------------\nPolitics & Government                    | 0.7763  \nInternational Affairs & Defense          | 0.7701  \nLaw & Justice                            | 0.4181 ⚠️\nEconomics & Finance                      | 0.7966  \nTrade & Business                         | 0.8538  \nEmployment & Labor                       | 0.4422 ⚠️\nSocial Affairs & Health                  | 0.6334  \nTechnology & Science                     | 0.6799  \nTransportation                           | 0.7649  \nEnvironment                              | 0.5053  \nAgriculture & Food                       | 0.9561  \nEnergy & Resources                       | 0.4959 ⚠️\nIndustry & Manufacturing                 | 0.5496  \nGeography & Regional                     | 0.8632  \n\n############################################################\n🏥 AUTOMATED MODEL DIAGNOSIS\n############################################################\n📉 Overall Overfitting Gap: 0.1772\n⚠️  High Overfitting detected overall.\n\n🔍 Detailed Class Analysis (Train vs Test F1):\nCategory                                 | Train   | Test    | Gap\n---------------------------------------------------------------------------\nPolitics & Government                    | 0.9475  | 0.7763  | +0.1711 \nInternational Affairs & Defense          | 0.9345  | 0.7701  | +0.1644 \nLaw & Justice                            | 0.9620  | 0.4181  | +0.5440 ⚠️ OVERFIT\nEconomics & Finance                      | 0.9449  | 0.7966  | +0.1484 \nTrade & Business                         | 0.9790  | 0.8538  | +0.1252 \nEmployment & Labor                       | 0.9722  | 0.4422  | +0.5300 ⚠️ OVERFIT\nSocial Affairs & Health                  | 0.9378  | 0.6334  | +0.3043 ⚠️ OVERFIT\nTechnology & Science                     | 0.9569  | 0.6799  | +0.2770 ⚠️ OVERFIT\nTransportation                           | 0.9713  | 0.7649  | +0.2064 ⚠️ OVERFIT\nEnvironment                              | 0.9756  | 0.5053  | +0.4703 ⚠️ OVERFIT\nAgriculture & Food                       | 0.9860  | 0.9561  | +0.0299 \nEnergy & Resources                       | 0.9800  | 0.4959  | +0.4841 ⚠️ OVERFIT\nIndustry & Manufacturing                 | 0.9471  | 0.5496  | +0.3975 ⚠️ OVERFIT\nGeography & Regional                     | 0.9633  | 0.8632  | +0.1002 \n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"booster = model.get_booster()\n\n\ntrees_df = booster.trees_to_dataframe()\n\nn_trees = trees_df['Tree'].max() + 1\nn_nodes = len(trees_df)\nn_leaves = len(trees_df[trees_df['Feature'] == 'Leaf'])\nn_splits = n_nodes - n_leaves\n\nprint(\"=\"*40)\nprint(\"📊 COMPLEXITÉ DU MODÈLE XGBOOST\")\nprint(\"=\"*40)\nprint(f\"Nombre total d'arbres :    {n_trees}\")\nprint(f\"Nombre total de nœuds :    {n_nodes} (Paramètres structurels)\")\nprint(f\"Nombre total de feuilles : {n_leaves} (Poids w appris)\")\nprint(f\"Nombre de décisions (splits): {n_splits}\")\nprint(\"-\" * 40)\nprint(f\"Moyenne de feuilles par arbre : {n_leaves / n_trees:.1f}\")\nprint(\"=\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:31:05.907885Z","iopub.execute_input":"2026-01-05T03:31:05.908316Z","iopub.status.idle":"2026-01-05T03:31:15.540347Z","shell.execute_reply.started":"2026-01-05T03:31:05.908291Z","shell.execute_reply":"2026-01-05T03:31:15.539717Z"}},"outputs":[{"name":"stdout","text":"========================================\n📊 COMPLEXITÉ DU MODÈLE XGBOOST\n========================================\nNombre total d'arbres :    7000\nNombre total de nœuds :    838744 (Paramètres structurels)\nNombre total de feuilles : 422872 (Poids w appris)\nNombre de décisions (splits): 415872\n----------------------------------------\nMoyenne de feuilles par arbre : 60.4\n========================================\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"filename = \"mon_modele_xgboost.pkl\"\njoblib.dump(model, filename)\n\nsize_bytes = os.path.getsize(filename)\nsize_mb = size_bytes / (1024 * 1024)\n\nprint(f\"💾 Taille physique du modèle sur disque : {size_mb:.2f} Mo\")\n\nif size_mb < 100:\n    print(\"✅ Modèle léger (Facile à déployer sur des petits serveurs/CPU)\")\nelse:\n    print(\"⚠️ Modèle lourd (Nécessite beaucoup de RAM)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T03:35:02.345341Z","iopub.execute_input":"2026-01-05T03:35:02.345969Z","iopub.status.idle":"2026-01-05T03:35:02.496009Z","shell.execute_reply.started":"2026-01-05T03:35:02.345945Z","shell.execute_reply":"2026-01-05T03:35:02.495398Z"}},"outputs":[{"name":"stdout","text":"💾 Taille physique du modèle sur disque : 31.60 Mo\n✅ Modèle léger (Facile à déployer sur des petits serveurs/CPU)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## Second approach : data augmentation ","metadata":{}},{"cell_type":"code","source":"# ==========================================\n# 1. DEFINE AUGMENTATION FUNCTION\n# ==========================================\ndef balance_multilabel_data(X, y, min_samples=3000):\n    \"\"\"\n    Iterates through each class. If a class has fewer than 'min_samples',\n    it randomly duplicates samples containing that label until the count is met.\n    \"\"\"\n    print(f\"🔄 Starting Augmentation (Target: {min_samples} samples per class)...\")\n    \n    # We work with copies to avoid messing up original data\n    X_aug = X.copy()\n    y_aug = y.copy()\n    \n    label_counts = y.sum(axis=0)\n    n_classes = y.shape[1]\n    \n    # Check which classes need help\n    rare_classes = [i for i in range(n_classes) if label_counts[i] < min_samples]\n    \n    if not rare_classes:\n        print(\"✅ No classes are below the threshold. No augmentation needed.\")\n        return X, y\n\n    print(f\"   Found {len(rare_classes)} rare classes needing augmentation.\")\n\n    for label_idx in rare_classes:\n        current_count = y_aug[:, label_idx].sum() # Recalculate as we grow the dataset\n        needed = min_samples - current_count\n        \n        if needed <= 0:\n            continue\n            \n        print(f\"   - Class {label_idx} ({id_code_mapping[label_idx] if 'id_code_mapping' in globals() else 'ID '+str(label_idx)}): Adding {int(needed)} samples...\")\n        \n        # Find indices of samples that have this specific label\n        # (Note: These samples might ALSO have frequent labels, that's okay)\n        rare_indices = np.where(y_aug[:, label_idx] == 1)[0]\n        \n        # If the class is empty in training (shouldn't happen), skip\n        if len(rare_indices) == 0:\n            continue\n            \n        # Randomly sample with replacement\n        new_indices = resample(rare_indices, n_samples=int(needed), replace=True, random_state=42)\n        \n        # Add the new samples to the big pile\n        X_new = X_aug[new_indices]\n        y_new = y_aug[new_indices]\n        \n        X_aug = np.vstack((X_aug, X_new))\n        y_aug = np.vstack((y_aug, y_new))\n        \n    print(f\"✅ Augmentation Complete.\")\n    print(f\"   Original Size: {X.shape[0]}\")\n    print(f\"   New Size:      {X_aug.shape[0]} (+{X_aug.shape[0] - X.shape[0]} samples)\")\n    \n    return X_aug, y_aug\n\n# ==========================================\n# 2. APPLY AUGMENTATION\n# ==========================================\n# Threshold: 2000 ensures even the smallest class (150 samples) gets a 10x boost\nX_train_aug, y_train_aug = balance_multilabel_data(X_train_svd, fixed_size_y_train, min_samples=2000)\n\n# ==========================================\n# 3. RETRAIN MODEL ON AUGMENTED DATA\n# ==========================================\nprint(\"\\n🚀 Retraining XGBoost on Augmented Data...\")\n\n# Re-initialize model with optimized parameters\nmodel_aug = XGBClassifier(\n    n_estimators=300,        # Good number for augmented data\n    max_depth=10,            \n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    objective=\"binary:logistic\",\n    \n    # GPU Parameters\n    tree_method=\"hist\",\n    device=\"cuda\",\n    \n    # Regularization \n    reg_alpha=10,\n    reg_lambda=10,\n    min_child_weight=3,\n    \n    random_state=42\n)\n\nmodel_aug.fit(X_train_aug, y_train_aug)\nprint(\"Training Complete!\")\n\n# ==========================================\n# 4. EVALUATE IMPROVEMENT\n# ==========================================\n# We use the evaluate_set function you defined earlier\n# IMPORTANT: Test on the ORIGINAL Test set, never augment the Test set!\ny_pred_aug, metrics_aug = evaluate_set(model_aug, X_test_svd, fixed_size_y_test, \"Test (Augmented)\", sorted_categories)\n\n# Print Final Comparison\nprint(\"\\n\" + \"=\"*50)\nprint(\"🔄 IMPACT OF AUGMENTATION (Test Set F1)\")\nprint(\"=\"*50)\n# Compare old metrics (test_metrics) vs new metrics (metrics_aug)\nif 'test_metrics' in globals():\n    gap = metrics_aug['micro_f1'] - test_metrics['micro_f1']\n    print(f\"Original Micro F1:  {test_metrics['micro_f1']:.4f}\")\n    print(f\"Augmented Micro F1: {metrics_aug['micro_f1']:.4f}\")\n    print(f\"Improvement:        {gap:+.4f}\")\n    if gap > 0:\n        print(\"✅ Augmentation improved the model!\")\n    else:\n        print(\"⚠️ No overall improvement (Common if duplicates cause overfitting). Check Macro F1.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T02:27:44.897516Z","iopub.execute_input":"2026-01-04T02:27:44.898087Z","iopub.status.idle":"2026-01-04T02:29:17.745710Z","shell.execute_reply.started":"2026-01-04T02:27:44.898065Z","shell.execute_reply":"2026-01-04T02:29:17.745045Z"}},"outputs":[{"name":"stdout","text":"🔄 Starting Augmentation (Target: 2000 samples per class)...\n   Found 3 rare classes needing augmentation.\n   - Class 2 (100169): Adding 682 samples...\n   - Class 5 (100172): Adding 113 samples...\n   - Class 11 (100179): Adding 880 samples...\n✅ Augmentation Complete.\n   Original Size: 55000\n   New Size:      56675 (+1675 samples)\n\n🚀 Retraining XGBoost on Augmented Data...\nTraining Complete!\n\n============================================================\n📊 TEST (AUGMENTED) SET EVALUATION\n============================================================\nGenerating predictions for Test (Augmented)...\nPredictions complete!\n\n--- Overall Metrics ---\nSubset Accuracy:     0.2566\nHamming Loss:        0.0916\nMicro F1 Score:      0.7841\nMacro F1 Score:      0.6614\n\n--- Per-Label F1 Scores (Test (Augmented)) ---\nCategory                                 | F1 Score\n-------------------------------------------------------\nPolitics & Government                    | 0.7013  \nInternational Affairs & Defense          | 0.7495  \nLaw & Justice                            | 0.2876 ⚠️\nEconomics & Finance                      | 0.8486  \nTrade & Business                         | 0.8644  \nEmployment & Labor                       | 0.4234 ⚠️\nSocial Affairs & Health                  | 0.6135  \nTechnology & Science                     | 0.6742  \nTransportation                           | 0.7467  \nEnvironment                              | 0.4794 ⚠️\nAgriculture & Food                       | 0.9600  \nEnergy & Resources                       | 0.5062  \nIndustry & Manufacturing                 | 0.5483  \nGeography & Regional                     | 0.8567  \n\n==================================================\n🔄 IMPACT OF AUGMENTATION (Test Set F1)\n==================================================\nOriginal Micro F1:  0.7748\nAugmented Micro F1: 0.7841\nImprovement:        +0.0093\n✅ Augmentation improved the model!\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"## current architecture process every class as an independent one, what is not the case, the labels can well correlate between each other ","metadata":{}},{"cell_type":"code","source":"\n\n# 1. Use Classifier Chains to model Label Correlations\n# This respects that \"Politics\" and \"International Relations\" are related.\nchain_model = ClassifierChain(\n    XGBClassifier(\n        n_estimators=500,\n        max_depth=15,             \n        learning_rate=0.05,\n        objective=\"binary:logistic\",\n        tree_method=\"hist\",\n        device=\"cuda\",\n        \n        # Regularization is still key\n        reg_alpha=10,\n        reg_lambda=10,\n        min_child_weight=3,\n        random_state=42\n    ),\n    order='random',\n    random_state=42\n)\n\nprint(\"🔗 Training Classifier Chain (Learning Label Dependencies)...\")\nchain_model.fit(X_train_svd, fixed_size_y_train)\nprint(\"Training Complete!\")\n\n# 2. Predict Probabilities instead of hard 0/1\n# We need probabilities to tune the thresholds later\ny_prob_test = chain_model.predict_proba(X_test_svd)\n\n# 3. Apply \"Task-Aware\" Thresholds\n# Instead of 0.5 for everything, we can be more lenient for rare classes\nthresholds = [0.5] * 14\n\n\n# 'Law & Justice' was weak, so we lower the bar.\nthresholds[2] = 0.35  \nthresholds[5] = 0.35  # Employment & Labor\n\nprint(\"🎯 Applying Per-Class Thresholds...\")\ny_pred_optimized = []\nfor sample_probs in y_prob_test:\n    # Apply threshold i to class i\n    row_pred = [1 if prob >= thresh else 0 for prob, thresh in zip(sample_probs, thresholds)]\n    y_pred_optimized.append(row_pred)\n\ny_pred_optimized = np.array(y_pred_optimized)\n\n# 4. Evaluate\n\n\n\n# Ensure categories are sorted correctly\nsorted_categories = sorted(categories_id.keys(), key=lambda k: categories_id[k])\n\ndef evaluate_chain_performance(y_true, y_pred, category_names):\n    \"\"\"\n    Comprehensive evaluation for the Classifier Chain model.\n    Highlights the performance of classes where we lowered the threshold.\n    \"\"\"\n    print(\"\\n\" + \"=\"*60)\n    print(\"🔗 CLASSIFIER CHAIN + OPTIMIZED THRESHOLDS EVALUATION\")\n    print(\"=\"*60)\n\n    # 1. Overall Metrics\n    subset_acc = accuracy_score(y_true, y_pred)\n    h_loss = hamming_loss(y_true, y_pred)\n    micro_f1 = f1_score(y_true, y_pred, average='micro')\n    macro_f1 = f1_score(y_true, y_pred, average='macro')\n    \n    print(f\"Subset Accuracy:     {subset_acc:.4f}  (Strict Exact Match)\")\n    print(f\"Hamming Loss:        {h_loss:.4f}\")\n    print(f\"Micro F1 Score:      {micro_f1:.4f}  (Overall Performance)\")\n    print(f\"Macro F1 Score:      {macro_f1:.4f}  (Average per Class - WATCH THIS)\")\n\n    # 2. Per-Class Analysis with Threshold Tracking\n    print(f\"\\n🔍 Detailed Per-Class Performance:\")\n    print(f\"{'Category':<40} | {'F1 Score'} | {'Threshold Used'}\")\n    print(\"-\" * 75)\n\n    per_label_f1 = f1_score(y_true, y_pred, average=None)\n    \n    # Reconstruct the thresholds list for display purposes\n    display_thresholds = [0.5] * 14\n    display_thresholds[2] = 0.35 # Law & Justice\n    display_thresholds[5] = 0.35 # Employment & Labor\n\n    for i, (cat, f1) in enumerate(zip(category_names, per_label_f1)):\n        thresh = display_thresholds[i]\n        \n        # Add visual markers\n        thresh_marker = \"🔧 LOW\" if thresh < 0.5 else \"  STD\"\n        score_marker = \"⚠️\" if f1 < 0.4 else \"✅\" if f1 > 0.7 else \" \"\n        \n        print(f\"{cat:<40} | {f1:.4f} {score_marker} | {thresh:.2f} {thresh_marker}\")\n\n    return micro_f1, macro_f1\n\n# ==========================================\n# EXECUTE EVALUATION\n# ==========================================\nchain_micro, chain_macro = evaluate_chain_performance(\n    fixed_size_y_test, \n    y_pred_optimized, \n    sorted_categories\n)\n\nprint(\"\\n\" + \"#\"*60)\nprint(\"🧐 FINAL ANALYSIS\")\nprint(\"#\"*60)\nprint(\"1. Did Classifier Chains help?\")\nprint(\"   - Check if 'Subset Accuracy' is higher than your previous ~0.2616.\")\nprint(\"   - Chains are designed to fix inconsistent label combinations.\")\n\nprint(\"\\n2. Did Lower Thresholds help Weak Classes?\")\nprint(\"   - Look at 'Law & Justice' and 'Employment & Labor'.\")\nprint(\"   - If their F1 is still < 0.4, try lowering thresholds further (e.g., to 0.25).\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T02:47:53.464023Z","iopub.execute_input":"2026-01-04T02:47:53.464647Z","iopub.status.idle":"2026-01-04T02:51:43.533481Z","shell.execute_reply.started":"2026-01-04T02:47:53.464621Z","shell.execute_reply":"2026-01-04T02:51:43.532712Z"}},"outputs":[{"name":"stdout","text":"🔗 Training Classifier Chain (Learning Label Dependencies)...\nTraining Complete!\n🎯 Applying Per-Class Thresholds...\n\n============================================================\n🔗 CLASSIFIER CHAIN + OPTIMIZED THRESHOLDS EVALUATION\n============================================================\nSubset Accuracy:     0.2558  (Strict Exact Match)\nHamming Loss:        0.0984\nMicro F1 Score:      0.7695  (Overall Performance)\nMacro F1 Score:      0.6556  (Average per Class - WATCH THIS)\n\n🔍 Detailed Per-Class Performance:\nCategory                                 | F1 Score | Threshold Used\n---------------------------------------------------------------------------\nPolitics & Government                    | 0.6797   | 0.50   STD\nInternational Affairs & Defense          | 0.7448 ✅ | 0.50   STD\nLaw & Justice                            | 0.3736 ⚠️ | 0.35 🔧 LOW\nEconomics & Finance                      | 0.6506   | 0.50   STD\nTrade & Business                         | 0.8633 ✅ | 0.50   STD\nEmployment & Labor                       | 0.4211   | 0.35 🔧 LOW\nSocial Affairs & Health                  | 0.6205   | 0.50   STD\nTechnology & Science                     | 0.6970   | 0.50   STD\nTransportation                           | 0.7523 ✅ | 0.50   STD\nEnvironment                              | 0.5095   | 0.50   STD\nAgriculture & Food                       | 0.9545 ✅ | 0.50   STD\nEnergy & Resources                       | 0.4874   | 0.50   STD\nIndustry & Manufacturing                 | 0.5613   | 0.50   STD\nGeography & Regional                     | 0.8631 ✅ | 0.50   STD\n\n############################################################\n🧐 FINAL ANALYSIS\n############################################################\n1. Did Classifier Chains help?\n   - Check if 'Subset Accuracy' is higher than your previous ~0.2616.\n   - Chains are designed to fix inconsistent label combinations.\n\n2. Did Lower Thresholds help Weak Classes?\n   - Look at 'Law & Justice' and 'Employment & Labor'.\n   - If their F1 is still < 0.4, try lowering thresholds further (e.g., to 0.25).\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"# This will download GloVe \n# It only downloads ONCE, then caches it\nprint(\"🔄 Downloading GloVe model... (this may take 2-3 minutes)\")\nprint(\"   Don't worry, this only happens once!\")\n\nglove_model = api.load('glove-wiki-gigaword-300') \n\nprint(\"\\n✅ Download complete!\")\nprint(f\"   Model has {len(glove_model):,} words in vocabulary\")\nprint(f\"   Each word is represented by {glove_model.vector_size} numbers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:18:09.671430Z","iopub.execute_input":"2026-01-04T01:18:09.672517Z","iopub.status.idle":"2026-01-04T01:20:47.813424Z","shell.execute_reply.started":"2026-01-04T01:18:09.672478Z","shell.execute_reply":"2026-01-04T01:20:47.812800Z"}},"outputs":[{"name":"stdout","text":"🔄 Downloading GloVe model... (this may take 2-3 minutes)\n   Don't worry, this only happens once!\n[========================--------------------------] 48.9% 183.9/376.1MB downloaded\n✅ Download complete!\n   Model has 400,000 words in vocabulary\n   Each word is represented by 300 numbers\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EMBEDDING_DIM = glove_model.vector_size\n\ndef text_to_glove(text, model):\n    words = text.lower().split()\n    vectors = [model[w] for w in words if w in model]\n\n    if not vectors:\n        return np.zeros(EMBEDDING_DIM)\n\n    return np.mean(vectors, axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:23:48.571779Z","iopub.execute_input":"2026-01-04T01:23:48.572501Z","iopub.status.idle":"2026-01-04T01:23:48.576750Z","shell.execute_reply.started":"2026-01-04T01:23:48.572449Z","shell.execute_reply":"2026-01-04T01:23:48.575939Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"X_train_glove = np.vstack([\n    text_to_glove(text, glove_model)\n    for text in X_train\n])\n\nX_val_glove = np.vstack([\n    text_to_glove(text, glove_model)\n    for text in X_val\n])\n\nX_test_glove = np.vstack([\n    text_to_glove(text, glove_model)\n    for text in X_test\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:23:48.890024Z","iopub.execute_input":"2026-01-04T01:23:48.890620Z","iopub.status.idle":"2026-01-04T01:25:36.598895Z","shell.execute_reply.started":"2026-01-04T01:23:48.890595Z","shell.execute_reply":"2026-01-04T01:25:36.598258Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"print(\"Train:\", X_train_glove.shape)\nprint(\"Val  :\", X_val_glove.shape)\nprint(\"Test :\", X_test_glove.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:26:39.712979Z","iopub.execute_input":"2026-01-04T01:26:39.713225Z","iopub.status.idle":"2026-01-04T01:26:39.717622Z","shell.execute_reply.started":"2026-01-04T01:26:39.713206Z","shell.execute_reply":"2026-01-04T01:26:39.716797Z"}},"outputs":[{"name":"stdout","text":"Train: (55000, 300)\nVal  : (5000, 300)\nTest : (5000, 300)\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"model = XGBClassifier(\n    n_estimators=300,       \n    max_depth=6,             \n    learning_rate=0.05,      \n    subsample=0.7,           \n    colsample_bytree=0.7,   \n\n    reg_alpha=0.1,           \n    reg_lambda=1.5,          \n    min_child_weight=3,    \n\n    # GPU Params \n    device=\"cuda\",\n    tree_method=\"hist\", \n    objective=\"binary:logistic\",\n    random_state=42\n)\n\n#model = ClassifierChain(base_model, order='random', random_state=42)\nmodel.fit(X_train_glove, fixed_size_y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:50:30.982388Z","iopub.execute_input":"2026-01-04T01:50:30.982714Z","iopub.status.idle":"2026-01-04T01:50:52.698330Z","shell.execute_reply.started":"2026-01-04T01:50:30.982692Z","shell.execute_reply":"2026-01-04T01:50:52.697715Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.7, device='cuda', early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=3, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=300, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.7, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=3, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=300, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=0.7, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=6, max_leaves=None,\n              min_child_weight=3, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=300, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"print(\"=\"*100)\nprint(\"🎯 COMPREHENSIVE EVALUATION: GloVe Embeddings\")\nprint(\"=\"*100)\n\nprint(f\"\\n📊 Dataset Shapes:\")\nprint(f\"   Train: {X_train_glove.shape}\")\nprint(f\"   Val  : {X_val_glove.shape}\")\nprint(f\"   Test : {X_test_glove.shape}\")\n\n# ============================================\n# GENERATE PREDICTIONS FOR ALL SETS\n# ============================================\nprint(\"\\n🔄 Generating predictions for all sets...\")\n\ny_train_pred = model.predict(X_train_glove)\ny_val_pred = model.predict(X_val_glove)\ny_test_pred = model.predict(X_test_glove)\n\nprint(\"✅ Predictions complete!\")\n\n# ============================================\n# EVALUATION FUNCTION\n# ============================================\ndef evaluate_set(y_true, y_pred, set_name):\n    \"\"\"Comprehensive evaluation metrics\"\"\"\n    \n    print(\"\\n\" + \"=\"*100)\n    print(f\"📈 {set_name.upper()} SET EVALUATION\")\n    print(\"=\"*100)\n    \n    # ============================================\n    # OVERALL METRICS\n    # ============================================\n    print(f\"\\n📊 Overall Metrics:\")\n    print(\"-\"*100)\n    \n    # Subset accuracy (exact match)\n    subset_acc = accuracy_score(y_true, y_pred)\n    \n    # Hamming loss\n    hamming = hamming_loss(y_true, y_pred)\n    \n    # F1 Scores\n    micro_f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n    weighted_f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n    samples_f1 = f1_score(y_true, y_pred, average='samples', zero_division=0)\n    \n    # Precision\n    micro_precision = precision_score(y_true, y_pred, average='micro', zero_division=0)\n    macro_precision = precision_score(y_true, y_pred, average='macro', zero_division=0)\n    weighted_precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n    \n    # Recall\n    micro_recall = recall_score(y_true, y_pred, average='micro', zero_division=0)\n    macro_recall = recall_score(y_true, y_pred, average='macro', zero_division=0)\n    weighted_recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n    \n    # Jaccard\n    jaccard_samples = jaccard_score(y_true, y_pred, average='samples', zero_division=0)\n    jaccard_macro = jaccard_score(y_true, y_pred, average='macro', zero_division=0)\n    jaccard_micro = jaccard_score(y_true, y_pred, average='micro', zero_division=0)\n    \n    # Print metrics table\n    print(f\"{'Metric':<30} | {'Micro':<12} | {'Macro':<12} | {'Weighted':<12} | {'Samples':<12}\")\n    print(\"-\"*100)\n    print(f\"{'F1 Score':<30} | {micro_f1:<12.4f} | {macro_f1:<12.4f} | {weighted_f1:<12.4f} | {samples_f1:<12.4f}\")\n    print(f\"{'Precision':<30} | {micro_precision:<12.4f} | {macro_precision:<12.4f} | {weighted_precision:<12.4f} | {'-':<12}\")\n    print(f\"{'Recall':<30} | {micro_recall:<12.4f} | {macro_recall:<12.4f} | {weighted_recall:<12.4f} | {'-':<12}\")\n    print(f\"{'Jaccard Score':<30} | {jaccard_micro:<12.4f} | {jaccard_macro:<12.4f} | {'-':<12} | {jaccard_samples:<12.4f}\")\n    \n    print(\"\\n\" + \"-\"*100)\n    print(f\"{'Subset Accuracy (Exact Match)':<30} | {subset_acc:<12.4f}\")\n    print(f\"{'Hamming Loss':<30} | {hamming:<12.4f}\")\n    \n    # Label-level statistics\n    avg_true_labels = y_true.sum(axis=1).mean()\n    avg_pred_labels = y_pred.sum(axis=1).mean()\n    std_true_labels = y_true.sum(axis=1).std()\n    std_pred_labels = y_pred.sum(axis=1).std()\n    \n    print(f\"\\n📊 Label Statistics:\")\n    print(\"-\"*100)\n    print(f\"Average labels per sample (True):     {avg_true_labels:.2f} ± {std_true_labels:.2f}\")\n    print(f\"Average labels per sample (Predicted): {avg_pred_labels:.2f} ± {std_pred_labels:.2f}\")\n    \n    # ============================================\n    # PER-CLASS METRICS\n    # ============================================\n    print(f\"\\n🎯 Per-Class Detailed Metrics:\")\n    print(\"-\"*100)\n    \n    category_names = list(categories_id.keys())\n    \n    per_class_f1 = f1_score(y_true, y_pred, average=None, zero_division=0)\n    per_class_precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n    per_class_recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n    per_class_jaccard = jaccard_score(y_true, y_pred, average=None, zero_division=0)\n    \n    # Support\n    support_true = y_true.sum(axis=0)\n    support_pred = y_pred.sum(axis=0)\n    \n    print(f\"{'Category':<40} | {'Support':<15} | {'Precision':<10} | {'Recall':<10} | {'F1':<10} | {'Jaccard':<10}\")\n    print(f\"{'':40} | {'True':<7}/{' Pred':<7} |\")\n    print(\"-\"*115)\n    \n    for i, cat_name in enumerate(category_names):\n        print(f\"{cat_name:<40} | {int(support_true[i]):>5} / {int(support_pred[i]):>5}   | \"\n              f\"{per_class_precision[i]:<10.4f} | {per_class_recall[i]:<10.4f} | \"\n              f\"{per_class_f1[i]:<10.4f} | {per_class_jaccard[i]:<10.4f}\")\n    \n    # ============================================\n    # PERFORMANCE CATEGORIES\n    # ============================================\n    print(f\"\\n📋 Performance Summary:\")\n    print(\"-\"*100)\n    \n    excellent = sum(per_class_f1 >= 0.8)\n    good = sum((per_class_f1 >= 0.6) & (per_class_f1 < 0.8))\n    moderate = sum((per_class_f1 >= 0.4) & (per_class_f1 < 0.6))\n    poor = sum(per_class_f1 < 0.4)\n    \n    print(f\"🌟 Excellent (F1 ≥ 0.8):    {excellent:2d}/14 classes\")\n    print(f\"✅ Good (0.6 ≤ F1 < 0.8):   {good:2d}/14 classes\")\n    print(f\"⚠️  Moderate (0.4 ≤ F1 < 0.6): {moderate:2d}/14 classes\")\n    print(f\"❌ Poor (F1 < 0.4):         {poor:2d}/14 classes\")\n    \n    # Return metrics for comparison\n    return {\n        'set_name': set_name,\n        'subset_accuracy': subset_acc,\n        'hamming_loss': hamming,\n        'micro_f1': micro_f1,\n        'macro_f1': macro_f1,\n        'weighted_f1': weighted_f1,\n        'samples_f1': samples_f1,\n        'micro_precision': micro_precision,\n        'macro_precision': macro_precision,\n        'micro_recall': micro_recall,\n        'macro_recall': macro_recall,\n        'jaccard_samples': jaccard_samples,\n        'per_class_f1': per_class_f1\n    }\n\n# ============================================\n# EVALUATE ALL SETS\n# ============================================\ntrain_results = evaluate_set(fixed_size_y_train, y_train_pred, \"Training\")\nval_results = evaluate_set(fixed_size_y_val, y_val_pred, \"Validation\")\ntest_results = evaluate_set(fixed_size_y_test, y_test_pred, \"Test\")\n\n# ============================================\n# CROSS-SET COMPARISON\n# ============================================\nprint(\"\\n\" + \"=\"*100)\nprint(\"🔍 CROSS-SET COMPARISON\")\nprint(\"=\"*100)\n\ncomparison_metrics = [\n    ('Subset Accuracy', 'subset_accuracy'),\n    ('Hamming Loss', 'hamming_loss'),\n    ('Micro F1', 'micro_f1'),\n    ('Macro F1', 'macro_f1'),\n    ('Weighted F1', 'weighted_f1'),\n    ('Samples F1', 'samples_f1'),\n    ('Micro Precision', 'micro_precision'),\n    ('Macro Precision', 'macro_precision'),\n    ('Micro Recall', 'micro_recall'),\n    ('Macro Recall', 'macro_recall'),\n    ('Jaccard (Samples)', 'jaccard_samples'),\n]\n\nprint(f\"\\n{'Metric':<25} | {'Training':<12} | {'Validation':<12} | {'Test':<12} | {'Train-Val':<12} | {'Val-Test':<12}\")\nprint(\"-\"*100)\n\nfor metric_name, metric_key in comparison_metrics:\n    train_val = train_results[metric_key]\n    val_val = val_results[metric_key]\n    test_val = test_results[metric_key]\n    \n    train_val_gap = abs(train_val - val_val)\n    val_test_gap = abs(val_val - test_val)\n    \n    print(f\"{metric_name:<25} | {train_val:<12.4f} | {val_val:<12.4f} | {test_val:<12.4f} | \"\n          f\"{train_val_gap:<12.4f} | {val_test_gap:<12.4f}\")\n\n# ============================================\n# OVERFITTING CHECK\n# ============================================\nprint(\"\\n\" + \"=\"*100)\nprint(\"⚠️  OVERFITTING ANALYSIS\")\nprint(\"=\"*100)\n\ntrain_test_gap = train_results['macro_f1'] - test_results['macro_f1']\ntrain_val_gap = train_results['macro_f1'] - val_results['macro_f1']\n\nprint(f\"\\nMacro F1 Gaps:\")\nprint(f\"  Train - Validation: {train_val_gap:+.4f}\")\nprint(f\"  Train - Test:       {train_test_gap:+.4f}\")\nprint(f\"  Validation - Test:  {val_results['macro_f1'] - test_results['macro_f1']:+.4f}\")\n\nif train_test_gap > 0.10:\n    print(f\"\\n🔴 SEVERE OVERFITTING DETECTED!\")\n    print(f\"   Model performs {train_test_gap:.1%} better on training than test\")\n    print(f\"   Recommendation: Increase regularization\")\nelif train_test_gap > 0.05:\n    print(f\"\\n⚠️  MODERATE OVERFITTING\")\n    print(f\"   Model performs {train_test_gap:.1%} better on training than test\")\n    print(f\"   Recommendation: Consider adding regularization\")\nelif train_test_gap < -0.05:\n    print(f\"\\n⚠️  UNDERFITTING\")\n    print(f\"   Test performance exceeds training by {abs(train_test_gap):.1%}\")\n    print(f\"   Recommendation: Increase model complexity\")\nelse:\n    print(f\"\\n✅ GOOD GENERALIZATION\")\n    print(f\"   Train-Test gap is reasonable ({train_test_gap:+.1%})\")\n\n# ============================================\n# PER-CLASS COMPARISON ACROSS SETS\n# ============================================\nprint(\"\\n\" + \"=\"*100)\nprint(\"📊 PER-CLASS F1 COMPARISON ACROSS SETS\")\nprint(\"=\"*100)\n\ncategory_names = list(categories_id.keys())\n\nprint(f\"\\n{'Category':<40} | {'Train':<10} | {'Val':<10} | {'Test':<10} | {'Best':<6} | {'Trend'}\")\nprint(\"-\"*100)\n\nfor i, cat_name in enumerate(category_names):\n    train_f1 = train_results['per_class_f1'][i]\n    val_f1 = val_results['per_class_f1'][i]\n    test_f1 = test_results['per_class_f1'][i]\n    \n    best = max(train_f1, val_f1, test_f1)\n    best_set = 'Train' if train_f1 == best else 'Val' if val_f1 == best else 'Test'\n    \n    # Determine trend\n    if test_f1 > val_f1 > train_f1:\n        trend = \"📈 Improving\"\n    elif test_f1 < val_f1 < train_f1:\n        trend = \"📉 Declining\"\n    elif abs(test_f1 - val_f1) < 0.02:\n        trend = \"➡️ Stable\"\n    else:\n        trend = \"🔄 Mixed\"\n    \n    print(f\"{cat_name:<40} | {train_f1:<10.4f} | {val_f1:<10.4f} | {test_f1:<10.4f} | {best_set:<6} | {trend}\")\n\n# ============================================\n# FINAL SUMMARY\n# ============================================\nprint(\"\\n\" + \"=\"*100)\nprint(\"✅ EVALUATION COMPLETE\")\nprint(\"=\"*100)\n\nprint(f\"\\n🎯 Key Takeaways:\")\nprint(f\"   Test Macro F1:       {test_results['macro_f1']:.4f}\")\nprint(f\"   Test Subset Accuracy: {test_results['subset_accuracy']:.4f}\")\nprint(f\"   Generalization Gap:  {train_test_gap:+.4f}\")\nprint(f\"   Classes with F1>0.8: {sum(test_results['per_class_f1'] >= 0.8)}/14\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T01:50:57.829109Z","iopub.execute_input":"2026-01-04T01:50:57.829872Z","iopub.status.idle":"2026-01-04T01:51:02.360885Z","shell.execute_reply.started":"2026-01-04T01:50:57.829846Z","shell.execute_reply":"2026-01-04T01:51:02.360253Z"}},"outputs":[{"name":"stdout","text":"====================================================================================================\n🎯 COMPREHENSIVE EVALUATION: GloVe Embeddings\n====================================================================================================\n\n📊 Dataset Shapes:\n   Train: (55000, 300)\n   Val  : (5000, 300)\n   Test : (5000, 300)\n\n🔄 Generating predictions for all sets...\n✅ Predictions complete!\n\n====================================================================================================\n📈 TRAINING SET EVALUATION\n====================================================================================================\n\n📊 Overall Metrics:\n----------------------------------------------------------------------------------------------------\nMetric                         | Micro        | Macro        | Weighted     | Samples     \n----------------------------------------------------------------------------------------------------\nF1 Score                       | 0.9249       | 0.9080       | 0.9228       | 0.9233      \nPrecision                      | 0.9522       | 0.9595       | 0.9515       | -           \nRecall                         | 0.8991       | 0.8650       | 0.8991       | -           \nJaccard Score                  | 0.8603       | 0.8360       | -            | 0.8802      \n\n----------------------------------------------------------------------------------------------------\nSubset Accuracy (Exact Match)  | 0.6733      \nHamming Loss                   | 0.0308      \n\n📊 Label Statistics:\n----------------------------------------------------------------------------------------------------\nAverage labels per sample (True):     2.95 ± 0.98\nAverage labels per sample (Predicted): 2.79 ± 0.92\n\n🎯 Per-Class Detailed Metrics:\n----------------------------------------------------------------------------------------------------\nCategory                                 | Support         | Precision  | Recall     | F1         | Jaccard   \n                                         | True   / Pred   |\n-------------------------------------------------------------------------------------------------------------------\nPolitics & Government                    | 14479 / 12322   | 0.9303     | 0.7917     | 0.8554     | 0.7474    \nInternational Affairs & Defense          |  9165 /  6918   | 0.9295     | 0.7016     | 0.7996     | 0.6661    \nLaw & Justice                            |  1318 /  1058   | 0.9943     | 0.7982     | 0.8855     | 0.7946    \nEconomics & Finance                      | 14201 / 12825   | 0.9421     | 0.8508     | 0.8941     | 0.8085    \nTrade & Business                         | 33539 / 33808   | 0.9473     | 0.9549     | 0.9511     | 0.9068    \nEmployment & Labor                       |  1854 /  1791   | 0.9978     | 0.9639     | 0.9805     | 0.9618    \nSocial Affairs & Health                  |  5670 /  5306   | 0.9365     | 0.8764     | 0.9054     | 0.8272    \nTechnology & Science                     |  7074 /  5556   | 0.9415     | 0.7395     | 0.8283     | 0.7070    \nTransportation                           |  3307 /  3087   | 0.9841     | 0.9187     | 0.9503     | 0.9052    \nEnvironment                              |  3104 /  2656   | 0.9842     | 0.8421     | 0.9076     | 0.8309    \nAgriculture & Food                       | 37255 / 37468   | 0.9828     | 0.9884     | 0.9856     | 0.9715    \nEnergy & Resources                       |  1101 /  1023   | 0.9980     | 0.9273     | 0.9614     | 0.9257    \nIndustry & Manufacturing                 |  6844 /  6061   | 0.9355     | 0.8285     | 0.8787     | 0.7837    \nGeography & Regional                     | 23346 / 23322   | 0.9295     | 0.9286     | 0.9290     | 0.8675    \n\n📋 Performance Summary:\n----------------------------------------------------------------------------------------------------\n🌟 Excellent (F1 ≥ 0.8):    13/14 classes\n✅ Good (0.6 ≤ F1 < 0.8):    1/14 classes\n⚠️  Moderate (0.4 ≤ F1 < 0.6):  0/14 classes\n❌ Poor (F1 < 0.4):          0/14 classes\n\n====================================================================================================\n📈 VALIDATION SET EVALUATION\n====================================================================================================\n\n📊 Overall Metrics:\n----------------------------------------------------------------------------------------------------\nMetric                         | Micro        | Macro        | Weighted     | Samples     \n----------------------------------------------------------------------------------------------------\nF1 Score                       | 0.8192       | 0.6905       | 0.8098       | 0.8178      \nPrecision                      | 0.8841       | 0.8101       | 0.8768       | -           \nRecall                         | 0.7632       | 0.6242       | 0.7632       | -           \nJaccard Score                  | 0.6938       | 0.5558       | -            | 0.7334      \n\n----------------------------------------------------------------------------------------------------\nSubset Accuracy (Exact Match)  | 0.3948      \nHamming Loss                   | 0.0779      \n\n📊 Label Statistics:\n----------------------------------------------------------------------------------------------------\nAverage labels per sample (True):     3.24 ± 1.05\nAverage labels per sample (Predicted): 2.79 ± 0.87\n\n🎯 Per-Class Detailed Metrics:\n----------------------------------------------------------------------------------------------------\nCategory                                 | Support         | Precision  | Recall     | F1         | Jaccard   \n                                         | True   / Pred   |\n-------------------------------------------------------------------------------------------------------------------\nPolitics & Government                    |  1726 /  1627   | 0.8095     | 0.7630     | 0.7856     | 0.6469    \nInternational Affairs & Defense          |  1163 /   808   | 0.8861     | 0.6156     | 0.7265     | 0.5705    \nLaw & Justice                            |   283 /   134   | 0.5672     | 0.2686     | 0.3645     | 0.2229    \nEconomics & Finance                      |  1530 /  1313   | 0.9383     | 0.8052     | 0.8667     | 0.7647    \nTrade & Business                         |  2924 /  2677   | 0.9122     | 0.8352     | 0.8720     | 0.7730    \nEmployment & Labor                       |   195 /   213   | 0.5211     | 0.5692     | 0.5441     | 0.3737    \nSocial Affairs & Health                  |   668 /   646   | 0.7198     | 0.6961     | 0.7078     | 0.5477    \nTechnology & Science                     |   809 /   517   | 0.7795     | 0.4981     | 0.6078     | 0.4366    \nTransportation                           |   511 /   373   | 0.9357     | 0.6830     | 0.7896     | 0.6523    \nEnvironment                              |   513 /   239   | 0.7238     | 0.3372     | 0.4601     | 0.2988    \nAgriculture & Food                       |  2958 /  2891   | 0.9803     | 0.9581     | 0.9691     | 0.9400    \nEnergy & Resources                       |   149 /    52   | 0.9231     | 0.3221     | 0.4776     | 0.3137    \nIndustry & Manufacturing                 |   644 /   446   | 0.7309     | 0.5062     | 0.5982     | 0.4267    \nGeography & Regional                     |  2105 /  2030   | 0.9138     | 0.8812     | 0.8972     | 0.8136    \n\n📋 Performance Summary:\n----------------------------------------------------------------------------------------------------\n🌟 Excellent (F1 ≥ 0.8):     4/14 classes\n✅ Good (0.6 ≤ F1 < 0.8):    5/14 classes\n⚠️  Moderate (0.4 ≤ F1 < 0.6):  4/14 classes\n❌ Poor (F1 < 0.4):          1/14 classes\n\n====================================================================================================\n📈 TEST SET EVALUATION\n====================================================================================================\n\n📊 Overall Metrics:\n----------------------------------------------------------------------------------------------------\nMetric                         | Micro        | Macro        | Weighted     | Samples     \n----------------------------------------------------------------------------------------------------\nF1 Score                       | 0.7909       | 0.6457       | 0.7833       | 0.7850      \nPrecision                      | 0.8579       | 0.7642       | 0.8574       | -           \nRecall                         | 0.7337       | 0.5839       | 0.7337       | -           \nJaccard Score                  | 0.6542       | 0.5128       | -            | 0.6919      \n\n----------------------------------------------------------------------------------------------------\nSubset Accuracy (Exact Match)  | 0.3408      \nHamming Loss                   | 0.0882      \n\n📊 Label Statistics:\n----------------------------------------------------------------------------------------------------\nAverage labels per sample (True):     3.18 ± 0.98\nAverage labels per sample (Predicted): 2.72 ± 0.80\n\n🎯 Per-Class Detailed Metrics:\n----------------------------------------------------------------------------------------------------\nCategory                                 | Support         | Precision  | Recall     | F1         | Jaccard   \n                                         | True   / Pred   |\n-------------------------------------------------------------------------------------------------------------------\nPolitics & Government                    |  1516 /  1569   | 0.7361     | 0.7619     | 0.7488     | 0.5984    \nInternational Affairs & Defense          |  1315 /   893   | 0.8981     | 0.6099     | 0.7264     | 0.5704    \nLaw & Justice                            |   243 /   142   | 0.3521     | 0.2058     | 0.2597     | 0.1493    \nEconomics & Finance                      |  1221 /  1020   | 0.9314     | 0.7781     | 0.8478     | 0.7359    \nTrade & Business                         |  2994 /  2802   | 0.9047     | 0.8467     | 0.8747     | 0.7774    \nEmployment & Labor                       |   155 /   181   | 0.2707     | 0.3161     | 0.2917     | 0.1707    \nSocial Affairs & Health                  |   683 /   738   | 0.5935     | 0.6413     | 0.6165     | 0.4456    \nTechnology & Science                     |   935 /   668   | 0.7919     | 0.5658     | 0.6600     | 0.4926    \nTransportation                           |   603 /   408   | 0.9265     | 0.6269     | 0.7478     | 0.5972    \nEnvironment                              |   609 /   283   | 0.7491     | 0.3481     | 0.4753     | 0.3118    \nAgriculture & Food                       |  2513 /  2386   | 0.9778     | 0.9284     | 0.9524     | 0.9092    \nEnergy & Resources                       |   170 /    47   | 0.8936     | 0.2471     | 0.3871     | 0.2400    \nIndustry & Manufacturing                 |   702 /   437   | 0.7529     | 0.4687     | 0.5777     | 0.4062    \nGeography & Regional                     |  2260 /  2039   | 0.9205     | 0.8305     | 0.8732     | 0.7750    \n\n📋 Performance Summary:\n----------------------------------------------------------------------------------------------------\n🌟 Excellent (F1 ≥ 0.8):     4/14 classes\n✅ Good (0.6 ≤ F1 < 0.8):    5/14 classes\n⚠️  Moderate (0.4 ≤ F1 < 0.6):  2/14 classes\n❌ Poor (F1 < 0.4):          3/14 classes\n\n====================================================================================================\n🔍 CROSS-SET COMPARISON\n====================================================================================================\n\nMetric                    | Training     | Validation   | Test         | Train-Val    | Val-Test    \n----------------------------------------------------------------------------------------------------\nSubset Accuracy           | 0.6733       | 0.3948       | 0.3408       | 0.2785       | 0.0540      \nHamming Loss              | 0.0308       | 0.0779       | 0.0882       | 0.0471       | 0.0103      \nMicro F1                  | 0.9249       | 0.8192       | 0.7909       | 0.1057       | 0.0283      \nMacro F1                  | 0.9080       | 0.6905       | 0.6457       | 0.2176       | 0.0448      \nWeighted F1               | 0.9228       | 0.8098       | 0.7833       | 0.1130       | 0.0265      \nSamples F1                | 0.9233       | 0.8178       | 0.7850       | 0.1055       | 0.0328      \nMicro Precision           | 0.9522       | 0.8841       | 0.8579       | 0.0682       | 0.0261      \nMacro Precision           | 0.9595       | 0.8101       | 0.7642       | 0.1494       | 0.0459      \nMicro Recall              | 0.8991       | 0.7632       | 0.7337       | 0.1359       | 0.0295      \nMacro Recall              | 0.8650       | 0.6242       | 0.5839       | 0.2408       | 0.0403      \nJaccard (Samples)         | 0.8802       | 0.7334       | 0.6919       | 0.1468       | 0.0415      \n\n====================================================================================================\n⚠️  OVERFITTING ANALYSIS\n====================================================================================================\n\nMacro F1 Gaps:\n  Train - Validation: +0.2176\n  Train - Test:       +0.2624\n  Validation - Test:  +0.0448\n\n🔴 SEVERE OVERFITTING DETECTED!\n   Model performs 26.2% better on training than test\n   Recommendation: Increase regularization\n\n====================================================================================================\n📊 PER-CLASS F1 COMPARISON ACROSS SETS\n====================================================================================================\n\nCategory                                 | Train      | Val        | Test       | Best   | Trend\n----------------------------------------------------------------------------------------------------\nPolitics & Government                    | 0.8554     | 0.7856     | 0.7488     | Train  | 📉 Declining\nInternational Affairs & Defense          | 0.7996     | 0.7265     | 0.7264     | Train  | 📉 Declining\nLaw & Justice                            | 0.8855     | 0.3645     | 0.2597     | Train  | 📉 Declining\nEconomics & Finance                      | 0.8941     | 0.8667     | 0.8478     | Train  | 📉 Declining\nTrade & Business                         | 0.9511     | 0.8720     | 0.8747     | Train  | ➡️ Stable\nEmployment & Labor                       | 0.9805     | 0.5441     | 0.2917     | Train  | 📉 Declining\nSocial Affairs & Health                  | 0.9054     | 0.7078     | 0.6165     | Train  | 📉 Declining\nTechnology & Science                     | 0.8283     | 0.6078     | 0.6600     | Train  | 🔄 Mixed\nTransportation                           | 0.9503     | 0.7896     | 0.7478     | Train  | 📉 Declining\nEnvironment                              | 0.9076     | 0.4601     | 0.4753     | Train  | ➡️ Stable\nAgriculture & Food                       | 0.9856     | 0.9691     | 0.9524     | Train  | 📉 Declining\nEnergy & Resources                       | 0.9614     | 0.4776     | 0.3871     | Train  | 📉 Declining\nIndustry & Manufacturing                 | 0.8787     | 0.5982     | 0.5777     | Train  | 📉 Declining\nGeography & Regional                     | 0.9290     | 0.8972     | 0.8732     | Train  | 📉 Declining\n\n====================================================================================================\n✅ EVALUATION COMPLETE\n====================================================================================================\n\n🎯 Key Takeaways:\n   Test Macro F1:       0.6457\n   Test Subset Accuracy: 0.3408\n   Generalization Gap:  +0.2624\n   Classes with F1>0.8: 4/14\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}